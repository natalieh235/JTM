{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cpc_training_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS3zre3hVRaa",
        "outputId": "eab6b565-06db-4184-a601-50172822c0a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/DLProjects/JTM"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/DLProjects/JTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmv_AG1ws6Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d445f22-b8bf-424b-a2cf-7a633bffb4cb"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ebc587a8-e232-4538-79aa-4cf87e25d12b)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4W0oTBeW8q_",
        "outputId": "e950a9bd-f301-4982-ed48-25db548bbaf7"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.0.1)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.15.0)\n",
            "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.20.23)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.12.1)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.9.1)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.0.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0Ie8ZO5TVd",
        "outputId": "5f8b0783-5e4e-4e28-de2b-35d0149ea995"
      },
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=\"K5CvVquVZJNg9xfY2ip95FuoD\",\n",
        "    project_name=\"jtm\",\n",
        "    workspace=\"tiagocuervo\"\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/tiagocuervo/jtm/48eea7c4b34f41059803188280ac26b7\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0pN8vB4qV6"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w4ZEQ4r4s5p"
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import Sampler, BatchSampler\n",
        "import librosa\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AudioBatchData(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 rawAudioPath,\n",
        "                 metadataPath,\n",
        "                 sizeWindow,\n",
        "                 labelsBy='composer',\n",
        "                 outputPath=None,\n",
        "                 CHUNK_SIZE=1e9,\n",
        "                 NUM_CHUNKS_INMEM=2,\n",
        "                 useGPU=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            - rawAudioPath (string): path to the raw audio files\n",
        "            - metadataPath (string): path to the data set metadata (used to define labels)\n",
        "            - sizeWindow (int): size of the sliding window\n",
        "            - labelsBy (string): name of column in metadata according to which create labels\n",
        "            - outputPath (string): path to the directory where chunks are to be created or are stored\n",
        "            - CHUNK_SIZE (int): desired size in bytes of a chunk\n",
        "            - NUM_CHUNKS_INMEM (int): target maximal size chunks of data to load in memory at a time\n",
        "        \"\"\"\n",
        "        self.NUM_CHUNKS_INMEM = NUM_CHUNKS_INMEM\n",
        "        self.CHUNK_SIZE = CHUNK_SIZE\n",
        "        self.rawAudioPath = Path(rawAudioPath)\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.useGPU = useGPU\n",
        "\n",
        "        self.sequencesData = pd.read_csv(metadataPath, index_col='id')\n",
        "        self.sequencesData = self.sequencesData.sort_values(by=labelsBy)\n",
        "        self.sequencesData[labelsBy] = self.sequencesData[labelsBy].astype('category')\n",
        "        self.sequencesData[labelsBy] = self.sequencesData[labelsBy].cat.codes\n",
        "\n",
        "        self.totSize = self.sequencesData['length'].sum()\n",
        "        # print(\"Total size:\", self.totSize)\n",
        "        # print(\"Length of data set:\", self.__len__())\n",
        "\n",
        "        self.category = labelsBy\n",
        "\n",
        "        if outputPath is None:\n",
        "            self.chunksDir = self.rawAudioPath / labelsBy\n",
        "        else:\n",
        "            self.chunksDir = Path(outputPath) / labelsBy\n",
        "\n",
        "        if not os.path.exists(self.chunksDir):\n",
        "            os.makedirs(self.chunksDir)\n",
        "\n",
        "        packages2Load = [fileName for fileName in os.listdir(self.chunksDir) if\n",
        "                         re.match(r'chunk_.*[0-9]+.pickle', fileName)]\n",
        "\n",
        "        if len(packages2Load) == 0:\n",
        "            self._createChunks()\n",
        "            packages2Load = [fileName for fileName in os.listdir(self.chunksDir) if\n",
        "                             re.match(r'chunk_.*[0-9]+.pickle', fileName)]\n",
        "        else:\n",
        "            print(\"Chunks already exist at\", self.chunksDir)\n",
        "\n",
        "        self.packs = []\n",
        "        packOfChunks = []\n",
        "        for i, packagePath in enumerate(packages2Load):\n",
        "            packOfChunks.append(packagePath)\n",
        "            if (i + 1) % self.NUM_CHUNKS_INMEM == 0:\n",
        "                self.packs.append(packOfChunks)\n",
        "                packOfChunks = []\n",
        "        if len(packOfChunks) > 0:\n",
        "            self.packs.append(packOfChunks)\n",
        "\n",
        "        self.currentPack = -1\n",
        "        self.nextPack = 0\n",
        "        self.sequenceIdx = 0\n",
        "\n",
        "        self.data = None\n",
        "\n",
        "        self._loadNextPack(first=True)\n",
        "        self._loadNextPack()\n",
        "\n",
        "    def _createChunks(self):\n",
        "        print(\"Creating chunks at\", self.chunksDir)\n",
        "        pack = []\n",
        "        packIds = []\n",
        "        packageSize = 0\n",
        "        packageIdx = 0\n",
        "        for trackId in tqdm.tqdm(self.sequencesData.index):\n",
        "            sequence, samplingRate = librosa.load(self.rawAudioPath / (str(trackId) + '.wav'), sr=16000)\n",
        "            sequence = torch.tensor(sequence).float()\n",
        "            packIds.append(trackId)\n",
        "            pack.append(sequence)\n",
        "            packageSize += len(sequence) * 4\n",
        "            if packageSize >= self.CHUNK_SIZE:\n",
        "                print(f\"Saved pack {packageIdx}\")\n",
        "                with open(self.chunksDir / f'chunk_{packageIdx}.pickle', 'wb') as handle:\n",
        "                    pickle.dump(torch.cat(pack, dim=0), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "                with open(self.chunksDir / f'ids_{packageIdx}.pickle', 'wb') as handle:\n",
        "                    pickle.dump(packIds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "                pack = []\n",
        "                packIds = []\n",
        "                packageSize = 0\n",
        "                packageIdx += 1\n",
        "        print(f\"Saved pack {packageIdx}\")\n",
        "        with open(self.chunksDir / f'chunk_{packageIdx}.pickle', 'wb') as handle:\n",
        "            pickle.dump(torch.cat(pack, dim=0), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.chunksDir / f'ids_{packageIdx}.pickle', 'wb') as handle:\n",
        "            pickle.dump(packIds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def _loadNextPack(self, first=False):\n",
        "        self.clear()\n",
        "        if not first:\n",
        "            self.currentPack = self.nextPack\n",
        "            startTime = time.time()\n",
        "            print('Loading files')\n",
        "            self.categoryLabel = [0]\n",
        "            packageIdx = [0]\n",
        "            self.seqLabel = [0]\n",
        "            packageSize = 0\n",
        "            previousCategory = 0\n",
        "            for packagePath in self.packs[self.currentPack]:\n",
        "                with open(self.chunksDir / ('ids_' + packagePath.split('_', maxsplit=1)[-1]), 'rb') as handle:\n",
        "                    chunkIds = pickle.load(handle)\n",
        "                for seqId in chunkIds:\n",
        "                    currentCategory = self.sequencesData.loc[seqId][self.category]\n",
        "                    if currentCategory != previousCategory:\n",
        "                        self.categoryLabel.append(packageSize)\n",
        "                    previousCategory = currentCategory\n",
        "                    packageSize += self.sequencesData.loc[seqId].length\n",
        "                    self.seqLabel.append(packageSize)\n",
        "                packageIdx.append(packageSize)\n",
        "\n",
        "            self.data = torch.empty(size=(packageSize,))\n",
        "            if self.useGPU:\n",
        "                self.data.cuda()\n",
        "            \n",
        "            for i, packagePath in enumerate(self.packs[self.currentPack]):\n",
        "                with open(self.chunksDir / packagePath, 'rb') as handle:\n",
        "                    self.data[packageIdx[i]:packageIdx[i + 1]] = pickle.load(handle)\n",
        "            print(f'Loaded {len(self.seqLabel) - 1} sequences, elapsed={time.time() - startTime:.3f} secs')\n",
        "\n",
        "        self.nextPack = (self.currentPack + 1) % len(self.packs)\n",
        "        if self.nextPack == 0 and len(self.packs) > 1:\n",
        "            self.currentPack = -1\n",
        "            self.nextPack = 0\n",
        "            self.sequenceIdx = 0\n",
        "\n",
        "    def clear(self):\n",
        "        if 'data' in self.__dict__:\n",
        "            del self.data\n",
        "        if 'categoryLabel' in self.__dict__:\n",
        "            del self.categoryLabel\n",
        "        if 'seqLabel' in self.__dict__:\n",
        "            del self.seqLabel\n",
        "\n",
        "    def getCategoryLabel(self, idx):\n",
        "        idCategory = next(x[0] for x in enumerate(self.categoryLabel) if x[1] > idx) - 1\n",
        "        return idCategory\n",
        "\n",
        "    def getSequenceLabel(self, idx):\n",
        "        return self.categoryLabel[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.totSize // self.sizeWindow\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < 0 or idx >= len(self.data) - self.sizeWindow - 1:\n",
        "            print(idx)\n",
        "\n",
        "        outData = self.data[idx:(self.sizeWindow + idx)].view(1, -1)\n",
        "        label = torch.tensor(self.getCategoryLabel(idx), dtype=torch.long)\n",
        "        return outData, label\n",
        "\n",
        "    def getBaseSampler(self, samplingType, batchSize, offset):\n",
        "        if samplingType == \"samecategory\":\n",
        "            return SameTrackSampler(batchSize, self.categoryLabel, self.sizeWindow, offset)\n",
        "        if samplingType == \"samesequence\":\n",
        "            return SameTrackSampler(batchSize, self.seqLabel, self.sizeWindow, offset)\n",
        "        if samplingType == \"sequential\":\n",
        "            return SequentialSampler(len(self.data), self.sizeWindow, offset, batchSize)\n",
        "\n",
        "        sampler = UniformAudioSampler(len(self.data), self.sizeWindow, offset)\n",
        "        return BatchSampler(sampler, batchSize, True)\n",
        "\n",
        "    def getDataLoader(self, batchSize, samplingType, randomOffset, numWorkers=0,\n",
        "                      onLoop=-1):\n",
        "        r\"\"\"\n",
        "        Get a batch sampler for the current dataset.\n",
        "            - batchSize (int): batch size\n",
        "            - groupSize (int): in the case of type in [\"track\", \"sequence\"]\n",
        "            number of items sharing a same label in the group\n",
        "            (see AudioBatchSampler)\n",
        "            - type (string):\n",
        "                type == \"track\": grouped sampler track-wise\n",
        "                type == \"sequence\": grouped sampler sequence-wise\n",
        "                type == \"sequential\": sequential sampling\n",
        "                else: uniform random sampling of the full audio\n",
        "                vector\n",
        "            - randomOffset (bool): if True add a random offset to the sampler\n",
        "                                   at the begining of each iteration\n",
        "        \"\"\"\n",
        "        nLoops = len(self.packs)\n",
        "        totSize = self.totSize // (self.sizeWindow * batchSize)\n",
        "        if onLoop >= 0:\n",
        "            self.currentPack = onLoop - 1\n",
        "            self._loadNextPack()\n",
        "            nLoops = 1\n",
        "\n",
        "        def samplerCall():\n",
        "            offset = random.randint(0, self.sizeWindow // 2) \\\n",
        "                if randomOffset else 0\n",
        "            return self.getBaseSampler(samplingType, batchSize, offset)\n",
        "\n",
        "        return AudioLoader(self, samplerCall, nLoops, self._loadNextPack, totSize, numWorkers)\n",
        "\n",
        "\n",
        "class AudioLoader(object):\n",
        "    r\"\"\"\n",
        "    A DataLoader meant to handle an AudioBatchData object.\n",
        "    In order to handle big datasets AudioBatchData works with big chunks of\n",
        "    audio it loads sequentially in memory: once all batches have been sampled\n",
        "    on a chunk, the AudioBatchData loads the next one.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 samplerCall,\n",
        "                 nLoop,\n",
        "                 updateCall,\n",
        "                 size,\n",
        "                 numWorkers):\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            - dataset (AudioBatchData): target dataset\n",
        "            - samplerCall (function): batch-sampler to call\n",
        "            - nLoop (int): number of chunks to load\n",
        "            - updateCall (function): function loading the next chunk\n",
        "            - size (int): total number of batches\n",
        "            - numWorkers (int): see torch.utils.data.DataLoader\n",
        "        \"\"\"\n",
        "        self.samplerCall = samplerCall\n",
        "        self.updateCall = updateCall\n",
        "        self.nLoop = nLoop\n",
        "        self.size = size\n",
        "        self.dataset = dataset\n",
        "        self.numWorkers = numWorkers\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        for i in range(self.nLoop):\n",
        "            sampler = self.samplerCall()\n",
        "            dataloader = DataLoader(self.dataset,\n",
        "                                    batch_sampler=sampler,\n",
        "                                    num_workers=self.numWorkers)\n",
        "            # print(\"Data loader nLoop: \", self.nLoop)\n",
        "            # print(\"Len data loader: \", len(dataloader))\n",
        "            # print(\"Len of sampler: \", len(sampler))\n",
        "            # assert False\n",
        "            # print(\"Dataloader len: \\n\", len(dataloader))\n",
        "            for j, x in enumerate(dataloader):\n",
        "                # print(\"Data loader yielded batch #: \", j)\n",
        "                yield x\n",
        "            # print(\"Len data loader: \", len(dataloader), \"and consummed: \", j + 1)\n",
        "            if i < self.nLoop - 1:\n",
        "                self.updateCall()\n",
        "\n",
        "\n",
        "class UniformAudioSampler(Sampler):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataSize,\n",
        "                 sizeWindow,\n",
        "                 offset):\n",
        "        self.len = dataSize // sizeWindow\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.offset = offset\n",
        "        if self.offset > 0:\n",
        "            self.len -= 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter((self.offset\n",
        "                     + self.sizeWindow * torch.randperm(self.len)).tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "class SequentialSampler(Sampler):\n",
        "\n",
        "    def __init__(self, dataSize, sizeWindow, offset, batchSize):\n",
        "\n",
        "        self.len = (dataSize // sizeWindow) // batchSize\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.offset = offset\n",
        "        self.startBatches = [x * (dataSize // batchSize)\n",
        "                             for x in range(batchSize)]\n",
        "        self.batchSize = batchSize\n",
        "        if self.offset > 0:\n",
        "            self.len -= 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in range(self.len):\n",
        "            yield [self.offset + self.sizeWindow * idx\n",
        "                   + start for start in self.startBatches]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "class SameTrackSampler(Sampler):\n",
        "\n",
        "    def __init__(self,\n",
        "                 batchSize,\n",
        "                 samplingIntervals,\n",
        "                 sizeWindow,\n",
        "                 offset):\n",
        "\n",
        "        self.samplingIntervals = samplingIntervals\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.batchSize = batchSize\n",
        "        self.offset = offset\n",
        "\n",
        "        if self.samplingIntervals[0] != 0:\n",
        "            raise AttributeError(\"Sampling intervals should start at zero\")\n",
        "\n",
        "        nWindows = len(self.samplingIntervals) - 1\n",
        "        self.sizeSamplers = [(self.samplingIntervals[i + 1] -\n",
        "                              self.samplingIntervals[i]) // self.sizeWindow\n",
        "                             for i in range(nWindows)]  # How many windows a sequence/category lasts \n",
        "\n",
        "        # assert False\n",
        "        if self.offset > 0:\n",
        "            self.sizeSamplers = [max(0, x - 1) for x in self.sizeSamplers]\n",
        "        # print(\"Size samplers:\\n\", self.sizeSamplers)\n",
        "        # print(\"Size samplers over batch size:\\n\", np.array(self.sizeSamplers) // self.batchSize)\n",
        "\n",
        "        order = [(x, torch.randperm(val).tolist())\n",
        "                 for x, val in enumerate(self.sizeSamplers) if\n",
        "                 val > 0]  # (index of seq/cat, randomly permuted numbers from 0 to num windows in seq(cat))\n",
        "\n",
        "        # Build Batches\n",
        "        self.batches = []\n",
        "        for indexSampler, randperm in order:\n",
        "            indexStart, sizeSampler = 0, self.sizeSamplers[indexSampler]\n",
        "            while indexStart < (sizeSampler - self.batchSize):\n",
        "                indexEnd = indexStart + self.batchSize\n",
        "                locBatch = [self.getIndex(x, indexSampler)\n",
        "                            for x in randperm[indexStart:indexEnd]]\n",
        "                indexStart = indexEnd\n",
        "                self.batches.append(locBatch)\n",
        "        # print(\"Number of batches:\\n\", len(self.batches))\n",
        "        # print(\"Batches:\\n\", self.batches)\n",
        "        # print(\"Batches shape: \\n\", np.array(self.batches).shape)\n",
        "        # print(\"Batches vstack shape: \\n\", np.vstack(self.batches).shape)\n",
        "        self.batches = np.vstack(self.batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batches)\n",
        "\n",
        "    def getIndex(self, x, iInterval):\n",
        "        return self.offset + x * self.sizeWindow + self.samplingIntervals[iInterval]\n",
        "\n",
        "    def __iter__(self):\n",
        "        random.shuffle(self.batches)\n",
        "        return iter(self.batches)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMMWgc3M4xln"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbjSx6SH4yo1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "class ChannelNorm(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 numFeatures,\n",
        "                 epsilon=1e-05,\n",
        "                 affine=True):\n",
        "\n",
        "        super(ChannelNorm, self).__init__()\n",
        "        if affine:\n",
        "            self.weight = nn.parameter.Parameter(torch.Tensor(1,\n",
        "                                                              numFeatures, 1))\n",
        "            self.bias = nn.parameter.Parameter(torch.Tensor(1, numFeatures, 1))\n",
        "        else:\n",
        "            self.weight = None\n",
        "            self.bias = None\n",
        "        self.epsilon = epsilon\n",
        "        self.p = 0\n",
        "        self.affine = affine\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.affine:\n",
        "            torch.nn.init.ones_(self.weight)\n",
        "            torch.nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        cumMean = x.mean(dim=1, keepdim=True)\n",
        "        cumVar = x.var(dim=1, keepdim=True)\n",
        "        x = (x - cumMean) * torch.rsqrt(cumVar + self.epsilon)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            x = x * self.weight + self.bias\n",
        "        return x\n",
        "\n",
        "\n",
        "class SincConv1D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, \n",
        "                 padding_mode='zeros', sampleRate=16000, minLowHz=50, minBandHz=50):\n",
        "        super(SincConv1D, self).__init__()\n",
        "        if in_channels != 1:\n",
        "            msg = \"SincConv1D only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "        self.outChannels = out_channels\n",
        "        self.kernelSize = kernel_size\n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if self.kernelSize % 2 == 0:\n",
        "            self.kernelSize += 1\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        if bias:\n",
        "            raise ValueError('SincConv1D does not support bias.')\n",
        "        if groups > 1:\n",
        "            raise ValueError('SincConv1D does not support groups.')\n",
        "        self.sampleRate = sampleRate\n",
        "        self.minLowHz = minLowHz\n",
        "        self.minBandHz = minBandHz\n",
        "        # Initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        lowHz = 30\n",
        "        highHz = self.sampleRate / 2 - (self.minLowHz + self.minBandHz)\n",
        "        mel = np.linspace(self.hz2Mel(lowHz), self.hz2Mel(highHz), self.outChannels + 1)\n",
        "        hz = self.mel2Hz(mel)\n",
        "        # Filter lower frequency (outChannels, 1)\n",
        "        self.lowHz_ = torch.nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "        # Filter frequency band (outChannels, 1)\n",
        "        self.bandHz_ = torch.nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "        # Hamming window\n",
        "        nLin= torch.linspace(0, (self.kernelSize / 2) - 1, \n",
        "                             steps=int((self.kernelSize / 2))) # computing only half of the window\n",
        "        self.window_ = 0.54 - 0.46 * torch.cos(2 * math.pi * nLin / self.kernelSize);\n",
        "        n = (self.kernelSize - 1) / 2.0\n",
        "        self.n_ = 2 * math.pi * torch.arange(-n, 0).view(1, -1) / self.sampleRate # Due to symmetry, we only need half of the time axes\n",
        "    \n",
        "    @staticmethod\n",
        "    def hz2Mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def mel2Hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "        low = self.minLowHz  + torch.abs(self.lowHz_)\n",
        "        high = torch.clamp(low + self.minBandHz + torch.abs(self.bandHz_), self.minLowHz, self.sampleRate/2)\n",
        "        band = (high - low)[:, 0]\n",
        "        fTimesTLow = torch.matmul(low, self.n_)\n",
        "        fTimesTHigh = torch.matmul(high, self.n_)\n",
        "        # Equivalent of Eq.4 of the reference paper\n",
        "        bandPassLeft = ((torch.sin(fTimesTHigh) - torch.sin(fTimesTLow)) / (self.n_/2)) * self.window_ \n",
        "        bandPassCenter = 2 * band.view(-1, 1)\n",
        "        bandPassRight = torch.flip(bandPassLeft, dims=[1])\n",
        "        bandPass = torch.cat([bandPassLeft, bandPassCenter, bandPassRight], dim=1)\n",
        "        bandPass = bandPass / (2 * band[:, None])\n",
        "        self.filters = (bandPass).view(self.outChannels, 1, self.kernelSize)\n",
        "        return torch.conv1d(waveforms, self.filters, stride=self.stride, padding=self.padding, \n",
        "                            dilation=self.dilation, bias=None, groups=1) \n",
        "\n",
        "\n",
        "class SincNetEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sizeHidden=512,\n",
        "                 normMode=\"layerNorm\"):\n",
        "        super(SincNetEncoder, self).__init__()     \n",
        "        normLayer = ChannelNorm\n",
        "        self.dimEncoded = sizeHidden\n",
        "        self.conv0 = SincConv1D(1, sizeHidden, 10, stride=5, padding=3)\n",
        "        self.batchNorm0 = normLayer(sizeHidden)\n",
        "\n",
        "\n",
        "\n",
        "class CPCEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 sizeHidden=512,\n",
        "                 normMode=\"layerNorm\", sincNet=False):\n",
        "\n",
        "        super(CPCEncoder, self).__init__()\n",
        "\n",
        "        validModes = [\"batchNorm\", \"instanceNorm\", \"ID\", \"layerNorm\"]\n",
        "        if normMode not in validModes:\n",
        "            raise ValueError(f\"Norm mode must be in {validModes}\")\n",
        "\n",
        "        if normMode == \"instanceNorm\":\n",
        "            def normLayer(x):\n",
        "                return nn.InstanceNorm1d(x, affine=True)\n",
        "        elif normMode == \"layerNorm\":\n",
        "            normLayer = ChannelNorm\n",
        "        else:\n",
        "            normLayer = nn.BatchNorm1d\n",
        "\n",
        "        self.dimEncoded = sizeHidden\n",
        "        if sincNet:\n",
        "            self.conv0 = SincConv1D(1, sizeHidden, 10, stride=5, padding=3)\n",
        "        else:\n",
        "            self.conv0 = nn.Conv1d(1, sizeHidden, 10, stride=5, padding=3)\n",
        "        self.batchNorm0 = normLayer(sizeHidden)\n",
        "        self.conv1 = nn.Conv1d(sizeHidden, sizeHidden, 8, stride=4, padding=2)\n",
        "        self.batchNorm1 = normLayer(sizeHidden)\n",
        "        self.conv2 = nn.Conv1d(sizeHidden, sizeHidden, 4,\n",
        "                               stride=2, padding=1)\n",
        "        self.batchNorm2 = normLayer(sizeHidden)\n",
        "        self.conv3 = nn.Conv1d(sizeHidden, sizeHidden, 4, stride=2, padding=1)\n",
        "        self.batchNorm3 = normLayer(sizeHidden)\n",
        "        self.conv4 = nn.Conv1d(sizeHidden, sizeHidden, 4, stride=2, padding=1)\n",
        "        self.batchNorm4 = normLayer(sizeHidden)\n",
        "        self.DOWNSAMPLING = 160\n",
        "\n",
        "    def getDimOutput(self):\n",
        "        return self.conv4.out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.batchNorm0(self.conv0(x)))\n",
        "        x = torch.relu(self.batchNorm1(self.conv1(x)))\n",
        "        x = torch.relu(self.batchNorm2(self.conv2(x)))\n",
        "        x = torch.relu(self.batchNorm3(self.conv3(x)))\n",
        "        x = torch.relu(self.batchNorm4(self.conv4(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class CPCAR(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dimEncoded,\n",
        "                 dimOutput,\n",
        "                 keepHidden,\n",
        "                 nLevelsGRU,\n",
        "                 mode=\"GRU\",\n",
        "                 reverse=False):\n",
        "\n",
        "        super(CPCAR, self).__init__()\n",
        "        self.RESIDUAL_STD = 0.1\n",
        "\n",
        "        if mode == \"LSTM\":\n",
        "            self.baseNet = nn.LSTM(dimEncoded, dimOutput,\n",
        "                                   num_layers=nLevelsGRU, batch_first=True)\n",
        "        elif mode == \"RNN\":\n",
        "            self.baseNet = nn.RNN(dimEncoded, dimOutput,\n",
        "                                  num_layers=nLevelsGRU, batch_first=True)\n",
        "        else:\n",
        "            self.baseNet = nn.GRU(dimEncoded, dimOutput,\n",
        "                                  num_layers=nLevelsGRU, batch_first=True)\n",
        "\n",
        "        self.hidden = None\n",
        "        self.keepHidden = keepHidden\n",
        "        self.reverse = reverse\n",
        "\n",
        "    def getDimOutput(self):\n",
        "        return self.baseNet.hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.reverse:\n",
        "            x = torch.flip(x, [1])\n",
        "        try:\n",
        "            self.baseNet.flatten_parameters()\n",
        "        except RuntimeError:\n",
        "            pass\n",
        "        x, h = self.baseNet(x, self.hidden)\n",
        "        if self.keepHidden:\n",
        "            if isinstance(h, tuple):\n",
        "                self.hidden = tuple(x.detach() for x in h)\n",
        "            else:\n",
        "                self.hidden = h.detach()\n",
        "\n",
        "        # For better modularity, a sequence's order should be preserved\n",
        "        # by each module\n",
        "        if self.reverse:\n",
        "            x = torch.flip(x, [1])\n",
        "        return x\n",
        "\n",
        "\n",
        "class CPCModel(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 AR):\n",
        "        super(CPCModel, self).__init__()\n",
        "        self.gEncoder = encoder\n",
        "        self.gAR = AR\n",
        "\n",
        "    def forward(self, batchData, label):\n",
        "        encodedData = self.gEncoder(batchData).permute(0, 2, 1)\n",
        "        cFeature = self.gAR(encodedData)\n",
        "        return cFeature, encodedData, label\n",
        "\n",
        "\n",
        "class PredictionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nPredicts,\n",
        "                 dimOutputAR,\n",
        "                 dimOutputEncoder,\n",
        "                 dropout=False):\n",
        "\n",
        "        super(PredictionNetwork, self).__init__()\n",
        "        self.predictors = nn.ModuleList()\n",
        "        self.RESIDUAL_STD = 0.01\n",
        "        self.dimOutputAR = dimOutputAR\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5) if dropout else None\n",
        "        for i in range(nPredicts):\n",
        "            self.predictors.append(\n",
        "                nn.Linear(dimOutputAR, dimOutputEncoder, bias=False))\n",
        "            if dimOutputEncoder > dimOutputAR:\n",
        "                residual = dimOutputEncoder - dimOutputAR\n",
        "                self.predictors[-1].weight.data.copy_(torch.cat([torch.randn(\n",
        "                    dimOutputAR, dimOutputAR), self.RESIDUAL_STD * torch.randn(residual, dimOutputAR)], dim=0))\n",
        "\n",
        "    def forward(self, c, candidates):\n",
        "\n",
        "        assert (len(candidates) == len(self.predictors))\n",
        "        out = []\n",
        "\n",
        "        # UGLY\n",
        "        # if isinstance(self.predictors[0], EqualizedConv1d):\n",
        "        # c = c.permute(0, 2, 1)\n",
        "\n",
        "        for k in range(len(self.predictors)):\n",
        "\n",
        "            locC = self.predictors[k](c)\n",
        "            if isinstance(locC, tuple):\n",
        "                locC = locC[0]\n",
        "            # if isinstance(self.predictors[k], EqualizedConv1d):\n",
        "            # locC = locC.permute(0, 2, 1)\n",
        "            if self.dropout is not None:\n",
        "                locC = self.dropout(locC)\n",
        "            locC = locC.view(locC.size(0), 1, locC.size(1), locC.size(2))\n",
        "            outK = (locC * candidates[k]).mean(dim=3)\n",
        "            out.append(outK)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BaseCriterion(nn.Module):\n",
        "    def update(self):\n",
        "        return\n",
        "\n",
        "\n",
        "class CPCUnsupersivedCriterion(BaseCriterion):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nPredicts,  # Number of steps\n",
        "                 dimOutputAR,  # Dimension of G_ar\n",
        "                 dimOutputEncoder,  # Dimension of the convolutional net\n",
        "                 negativeSamplingExt,  # Number of negative samples to draw\n",
        "                 mode=None,\n",
        "                 dropout=False):\n",
        "\n",
        "        super(CPCUnsupersivedCriterion, self).__init__()\n",
        "\n",
        "        self.wPrediction = PredictionNetwork(\n",
        "            nPredicts, dimOutputAR, dimOutputEncoder, dropout=dropout)\n",
        "        self.nPredicts = nPredicts\n",
        "        self.negativeSamplingExt = negativeSamplingExt\n",
        "        self.lossCriterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        if mode not in [None, \"reverse\"]:\n",
        "            raise ValueError(\"Invalid mode\")\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "    def sampleClean(self, encodedData, windowSize):\n",
        "\n",
        "        batchSize, nNegativeExt, dimEncoded = encodedData.size()\n",
        "        outputs = []\n",
        "\n",
        "        negExt = encodedData.contiguous().view(-1, dimEncoded)\n",
        "        # Draw nNegativeExt * batchSize negative samples anywhere in the batch\n",
        "        batchIdx = torch.randint(low=0, high=batchSize,\n",
        "                                 size=(self.negativeSamplingExt\n",
        "                                       * windowSize * batchSize,),\n",
        "                                 device=encodedData.device)\n",
        "\n",
        "        seqIdx = torch.randint(low=1, high=nNegativeExt,\n",
        "                               size=(self.negativeSamplingExt\n",
        "                                     * windowSize * batchSize,),\n",
        "                               device=encodedData.device)\n",
        "\n",
        "        baseIdx = torch.arange(0, windowSize, device=encodedData.device)\n",
        "        baseIdx = baseIdx.view(1, 1,\n",
        "                               windowSize).expand(1,\n",
        "                                                  self.negativeSamplingExt,\n",
        "                                                  windowSize).expand(batchSize, self.negativeSamplingExt, windowSize)\n",
        "        seqIdx += baseIdx.contiguous().view(-1)\n",
        "        seqIdx = torch.remainder(seqIdx, nNegativeExt)\n",
        "\n",
        "        extIdx = seqIdx + batchIdx * nNegativeExt\n",
        "        negExt = negExt[extIdx].view(batchSize, self.negativeSamplingExt,\n",
        "                                     windowSize, dimEncoded)\n",
        "\n",
        "        labelLoss = torch.zeros((batchSize * windowSize),\n",
        "                                dtype=torch.long,\n",
        "                                device=encodedData.device)\n",
        "\n",
        "        for k in range(1, self.nPredicts + 1):\n",
        "\n",
        "            # Positive samples\n",
        "            if k < self.nPredicts:\n",
        "                posSeq = encodedData[:, k:-(self.nPredicts - k)]\n",
        "            else:\n",
        "                posSeq = encodedData[:, k:]\n",
        "\n",
        "            posSeq = posSeq.view(batchSize, 1, windowSize, dimEncoded)\n",
        "            fullSeq = torch.cat((posSeq, negExt), dim=1)\n",
        "            outputs.append(fullSeq)\n",
        "\n",
        "        return outputs, labelLoss\n",
        "\n",
        "    def getInnerLoss(self):\n",
        "\n",
        "        return \"orthoLoss\", self.orthoLoss * self.wPrediction.orthoCriterion()\n",
        "\n",
        "    def forward(self, cFeature, encodedData):\n",
        "\n",
        "        if self.mode == \"reverse\":\n",
        "            encodedData = torch.flip(encodedData, [1])\n",
        "            cFeature = torch.flip(cFeature, [1])\n",
        "\n",
        "        batchSize, seqSize, dimAR = cFeature.size()\n",
        "        windowSize = seqSize - self.nPredicts\n",
        "\n",
        "        cFeature = cFeature[:, :windowSize]\n",
        "\n",
        "        sampledData, labelLoss = self.sampleClean(encodedData, windowSize)\n",
        "\n",
        "        predictions = self.wPrediction(cFeature, sampledData)\n",
        "\n",
        "        outLosses = [0 for _ in range(self.nPredicts)]\n",
        "        outAcc = [0 for _ in range(self.nPredicts)]\n",
        "\n",
        "        for k, locPreds in enumerate(predictions[:self.nPredicts]):\n",
        "            locPreds = locPreds.permute(0, 2, 1)  # (batchSize, 1 + negativeSamplingExt, windowSize) to\n",
        "            #                                       (batchSize, windowSize, 1 + negativeSamplingExt)\n",
        "            locPreds = locPreds.contiguous().view(\n",
        "                -1, locPreds.size(2))  # (batchSize, windowSize, 1 + negativeSamplingExt) to\n",
        "            #                            (batchSize * windowSize, 1 + negativeSamplingExt)\n",
        "            lossK = self.lossCriterion(locPreds, labelLoss)\n",
        "            outLosses[k] += lossK.view(1, -1)\n",
        "            _, predsIndex = locPreds.max(1)\n",
        "            outAcc[k] += torch.sum(predsIndex == labelLoss).float().view(1, -1)\n",
        "\n",
        "        return torch.cat(outLosses, dim=1), torch.cat(outAcc, dim=1) / (windowSize * batchSize)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_rcKRYDQDHW"
      },
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZR5tuFYQCeJ"
      },
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sizeSeq,         # Size of the input sequence\n",
        "                 dk,              # Dimension of the input sequence\n",
        "                 dropout,         # Dropout parameter\n",
        "                 relpos=False):   # Do we retrieve positional information ?\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "        self.relpos = relpos\n",
        "        self.sizeSeq = sizeSeq\n",
        "\n",
        "        if relpos:\n",
        "            self.Krelpos = nn.Parameter(torch.Tensor(dk, sizeSeq))\n",
        "            self.initmat_(self.Krelpos)\n",
        "            self.register_buffer('z', torch.zeros(1, sizeSeq, 1))\n",
        "\n",
        "        # A mask is set so that a node never queries data in the future\n",
        "        mask = torch.tril(torch.ones(sizeSeq, sizeSeq), diagonal=0)\n",
        "        mask = 1 - mask\n",
        "        mask[mask == 1] = -float('inf')\n",
        "        self.register_buffer('mask', mask.unsqueeze(0))\n",
        "\n",
        "    def initmat_(self, mat, dim=0):\n",
        "        stdv = 1. / math.sqrt(mat.size(dim))\n",
        "        mat.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        # Input dim : N x sizeSeq x dk\n",
        "        QK = torch.bmm(Q, K.transpose(-2, -1))\n",
        "\n",
        "        if self.relpos:\n",
        "            bsz = Q.size(0)\n",
        "            QP = Q.matmul(self.Krelpos)\n",
        "            # This trick with z fills QP's diagonal with zeros\n",
        "            QP = torch.cat((self.z.expand(bsz, -1, -1), QP), 2)\n",
        "            QK += QP.view(bsz, self.sizeSeq + 1, self.sizeSeq)[:, 1:, :]\n",
        "        A = self.softmax(QK / math.sqrt(K.size(-1)) + self.mask)\n",
        "        return torch.bmm(self.drop(A), V)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 sizeSeq,   # Size of a sequence\n",
        "                 dropout,   # Dropout parameter\n",
        "                 dmodel,    # Model's dimension\n",
        "                 nheads,    # Number of heads in the model\n",
        "                 abspos):   # Is positional information encoded in the input ?\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.Wo = nn.Linear(dmodel, dmodel, bias=False)\n",
        "        self.Wk = nn.Linear(dmodel, dmodel, bias=False)\n",
        "        self.Wq = nn.Linear(dmodel, dmodel, bias=False)\n",
        "        self.Wv = nn.Linear(dmodel, dmodel, bias=False)\n",
        "        self.nheads = nheads\n",
        "        self.dk = dmodel // nheads\n",
        "        self.Att = ScaledDotProductAttention(sizeSeq, self.dk,\n",
        "                                             dropout, not abspos)\n",
        "\n",
        "    def trans_(self, x):\n",
        "        bsz, bptt, h, dk = x.size(0), x.size(1), self.nheads, self.dk\n",
        "        return x.view(bsz, bptt, h, dk).transpose(1, 2).contiguous().view(bsz * h, bptt, dk)\n",
        "\n",
        "    def reverse_trans_(self, x):\n",
        "        bsz, bptt, h, dk = x.size(\n",
        "            0) // self.nheads, x.size(1), self.nheads, self.dk\n",
        "        return x.view(bsz, h, bptt, dk).transpose(1, 2).contiguous().view(bsz, bptt, h * dk)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        q = self.trans_(self.Wq(Q))\n",
        "        k = self.trans_(self.Wk(K))\n",
        "        v = self.trans_(self.Wv(V))\n",
        "        y = self.reverse_trans_(self.Att(q, k, v))\n",
        "        return self.Wo(y)\n",
        "\n",
        "\n",
        "class FFNetwork(nn.Module):\n",
        "    def __init__(self, din, dout, dff, dropout):\n",
        "        super(FFNetwork, self).__init__()\n",
        "        self.lin1 = nn.Linear(din, dff, bias=True)\n",
        "        self.lin2 = nn.Linear(dff, dout, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin2(self.drop(self.relu(self.lin1(x))))\n",
        "\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, sizeSeq=32, dmodel=512, dff=2048,\n",
        "                 dropout=0.1, nheads=8,\n",
        "                 abspos=False):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "        self.multihead = MultiHeadAttention(sizeSeq, dropout,\n",
        "                                            dmodel, nheads, abspos)\n",
        "        self.ln_multihead = nn.LayerNorm(dmodel)\n",
        "        self.ffnetwork = FFNetwork(dmodel, dmodel, dff, dropout)\n",
        "        self.ln_ffnetwork = nn.LayerNorm(dmodel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.ln_multihead(x + self.multihead(Q=x, K=x, V=x))\n",
        "        return self.ln_ffnetwork(y + self.ffnetwork(y))\n",
        "\n",
        "\n",
        "class StaticPositionEmbedding(nn.Module):\n",
        "    def __init__(self, seqlen, dmodel):\n",
        "        super(StaticPositionEmbedding, self).__init__()\n",
        "        pos = torch.arange(0., seqlen).unsqueeze(1).repeat(1, dmodel)\n",
        "        dim = torch.arange(0., dmodel).unsqueeze(0).repeat(seqlen, 1)\n",
        "        div = torch.exp(- math.log(10000) * (2*(dim//2)/dmodel))\n",
        "        pos *= div\n",
        "        pos[:, 0::2] = torch.sin(pos[:, 0::2])\n",
        "        pos[:, 1::2] = torch.cos(pos[:, 1::2])\n",
        "        self.register_buffer('pe', pos.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "\n",
        "def buildTransformerAR(dimEncoded,    # Output dimension of the encoder\n",
        "                       nLayers,       # Number of transformer layers\n",
        "                       sizeSeq,       # Expected size of the input sequence\n",
        "                       abspos):\n",
        "    layerSequence = []\n",
        "    if abspos:\n",
        "        layerSequence += [StaticPositionEmbedding(sizeSeq, dimEncoded)]\n",
        "    layerSequence += [TransformerLayer(sizeSeq=sizeSeq,\n",
        "                                       dmodel=dimEncoded, abspos=abspos)\n",
        "                      for i in range(nLayers)]\n",
        "    return nn.Sequential(*layerSequence)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhJSRs0F43UA"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtqKVS-444yK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from copy import deepcopy\n",
        "# import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "\n",
        "def update_logs(logs, logStep, prevlogs=None):\n",
        "    out = {}\n",
        "    for key in logs:\n",
        "        out[key] = deepcopy(logs[key])\n",
        "\n",
        "        if prevlogs is not None:\n",
        "            out[key] -= prevlogs[key]\n",
        "        out[key] /= logStep\n",
        "    return out\n",
        "\n",
        "\n",
        "def save_logs(data, pathLogs):\n",
        "    with open(pathLogs, 'w') as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "\n",
        "def save_checkpoint(model_state, criterion_state, optimizer_state, best_state,\n",
        "                    path_checkpoint):\n",
        "\n",
        "    state_dict = {\"gEncoder\": model_state,\n",
        "                  \"cpcCriterion\": criterion_state,\n",
        "                  \"optimizer\": optimizer_state,\n",
        "                  \"best\": best_state}\n",
        "\n",
        "    torch.save(state_dict, path_checkpoint)\n",
        "\n",
        "\n",
        "def show_logs(text, logs):\n",
        "    print(\"\")\n",
        "    print('-' * 50)\n",
        "    print(text)\n",
        "\n",
        "    for key in logs:\n",
        "\n",
        "        if key == \"iter\":\n",
        "            continue\n",
        "\n",
        "        nPredicts = logs[key].shape[0]\n",
        "\n",
        "        strSteps = ['Step'] + [str(s) for s in range(1, nPredicts + 1)]\n",
        "        formatCommand = ' '.join(['{:>16}' for _ in range(nPredicts + 1)])\n",
        "        print(formatCommand.format(*strSteps))\n",
        "\n",
        "        strLog = [key] + [\"{:10.6f}\".format(s) for s in logs[key]]\n",
        "        print(formatCommand.format(*strLog))\n",
        "\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "def trainStep(dataLoader,\n",
        "              cpcModel,\n",
        "              cpcCriterion,\n",
        "              optimizer,\n",
        "              loggingStep,\n",
        "              useGPU,\n",
        "              log2Board=0,\n",
        "              totalSteps=0):\n",
        "    cpcModel.train()\n",
        "    cpcCriterion.train()\n",
        "\n",
        "    startTime = time.perf_counter()\n",
        "    n_examples = 0\n",
        "    logs, lastlogs = {}, None\n",
        "    iterCtr = 0\n",
        "\n",
        "    if log2Board > 1:\n",
        "        gradmapGEncoder = {}\n",
        "        gradmapGAR = {}\n",
        "        gradmapWPrediction = {}\n",
        "        if totalSteps == 0:\n",
        "            logWeights(cpcModel.gEncoder, totalSteps)\n",
        "            logWeights(cpcModel.gAR, totalSteps)\n",
        "            logWeights(cpcCriterion.wPrediction, totalSteps)\n",
        "\n",
        "    for step, fulldata in enumerate(dataLoader):\n",
        "        batchData, label = fulldata\n",
        "        n_examples += batchData.size(0)\n",
        "        if useGPU:\n",
        "            batchData = batchData.cuda(non_blocking=True)\n",
        "            label = label.cuda(non_blocking=True)\n",
        "        c_feature, encoded_data, label = cpcModel(batchData, label)\n",
        "        allLosses, allAcc = cpcCriterion(c_feature, encoded_data)\n",
        "        totLoss = allLosses.sum()\n",
        "\n",
        "        totLoss.backward()\n",
        "\n",
        "        if log2Board > 1:\n",
        "            gradmapGEncoder = updateGradientMap(cpcModel.gEncoder, gradmapGEncoder)\n",
        "            gradmapGAR = updateGradientMap(cpcModel.gAR, gradmapGAR)\n",
        "            gradmapWPrediction = updateGradientMap(cpcCriterion.wPrediction, gradmapWPrediction)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if \"locLoss_train\" not in logs:\n",
        "            logs[\"locLoss_train\"] = np.zeros(allLosses.size(1))\n",
        "            logs[\"locAcc_train\"] = np.zeros(allLosses.size(1))\n",
        "\n",
        "        logs[\"locLoss_train\"] += (allLosses.mean(dim=0)).detach().cpu().numpy()\n",
        "        logs[\"locAcc_train\"] += (allAcc.mean(dim=0)).cpu().numpy()\n",
        "        iterCtr += 1\n",
        "\n",
        "        if log2Board:\n",
        "            for t in range(len(logs[\"locLoss_train\"])):\n",
        "                experiment.log_metric(f\"Losses/batch/locLoss_train_{t}\", logs[\"locLoss_train\"][t] / iterCtr, step=totalSteps + iterCtr)\n",
        "                experiment.log_metric(f\"Accuracy/batch/locAcc_train_{t}\", logs[\"locAcc_train\"][t] / iterCtr, step=totalSteps + iterCtr)\n",
        "\n",
        "        if (step + 1) % loggingStep == 0:\n",
        "            new_time = time.perf_counter()\n",
        "            elapsed = new_time - startTime\n",
        "            print(f\"Update {step + 1}\")\n",
        "            print(f\"elapsed: {elapsed:.1f} s\")\n",
        "            print(\n",
        "                f\"{1000.0 * elapsed / loggingStep:.1f} ms per batch, {1000.0 * elapsed / n_examples:.1f} ms / example\")\n",
        "            locLogs = update_logs(logs, loggingStep, lastlogs)\n",
        "            lastlogs = deepcopy(logs)\n",
        "            show_logs(\"Training loss\", locLogs)\n",
        "            startTime, n_examples = new_time, 0\n",
        "            \n",
        "            if log2Board > 1:\n",
        "                # Log gradients\n",
        "                logGradients(gradmapGEncoder, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                logGradients(gradmapGAR, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                logGradients(gradmapWPrediction, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                # Log weights\n",
        "                logWeights(cpcModel.gEncoder, totalSteps + iterCtr)\n",
        "                logWeights(cpcModel.gAR, totalSteps + iterCtr)\n",
        "                logWeights(cpcCriterion.wPrediction, totalSteps + iterCtr)\n",
        "\n",
        "    logs = update_logs(logs, iterCtr)\n",
        "    logs[\"iter\"] = iterCtr\n",
        "    show_logs(\"Average training loss on epoch\", logs)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def valStep(dataLoader,\n",
        "            cpcModel,\n",
        "            cpcCriterion,\n",
        "            useGPU):\n",
        "    cpcCriterion.eval()\n",
        "    cpcModel.eval()\n",
        "    logs = {}\n",
        "    cpcCriterion.eval()\n",
        "    cpcModel.eval()\n",
        "    iterCtr = 0\n",
        "\n",
        "    for step, fulldata in enumerate(dataLoader):\n",
        "\n",
        "        batchData, label = fulldata\n",
        "\n",
        "        if useGPU:\n",
        "            batchData = batchData.cuda(non_blocking=True)\n",
        "            label = label.cuda(non_blocking=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            c_feature, encoded_data, label = cpcModel(batchData, label)\n",
        "            allLosses, allAcc = cpcCriterion(c_feature, encoded_data)\n",
        "\n",
        "        if \"locLoss_val\" not in logs:\n",
        "            logs[\"locLoss_val\"] = np.zeros(allLosses.size(1))\n",
        "            logs[\"locAcc_val\"] = np.zeros(allLosses.size(1))\n",
        "\n",
        "        iterCtr += 1\n",
        "        logs[\"locLoss_val\"] += allLosses.mean(dim=0).cpu().numpy()\n",
        "        logs[\"locAcc_val\"] += allAcc.mean(dim=0).cpu().numpy()\n",
        "\n",
        "    logs = update_logs(logs, iterCtr)\n",
        "    logs[\"iter\"] = iterCtr\n",
        "    show_logs(\"Validation loss:\", logs)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def updateGradientMap(model, gradMap):\n",
        "    for name, param in model.named_parameters():\n",
        "        paramName = name.split('.')\n",
        "        paramLabel = paramName[-1]\n",
        "        if paramLabel not in ['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', \n",
        "                              'lowHz_', 'bandHz_', 'weight', 'bias']:\n",
        "            continue\n",
        "        param = model\n",
        "        for i in range(len(paramName)):\n",
        "            param = getattr(param, paramName[i])\n",
        "        gradMap.setdefault(\"%s/%s\" % (\"Gradients\", name), 0)\n",
        "        gradMap[\"%s/%s\" % (\"Gradients\", name)] += param.grad\n",
        "    return gradMap\n",
        "\n",
        "\n",
        "def logGradients(gradMap, step, scaleBy=1.0):\n",
        "    for k, v in gradMap.items():\n",
        "        experiment.log_histogram_3d(v.cpu().detach().numpy() * scaleBy, name=k, step=step)\n",
        "\n",
        "\n",
        "def logWeights(model, step):\n",
        "    for name, param in model.named_parameters():\n",
        "        paramName = name.split('.')\n",
        "        paramLabel = paramName[-1]\n",
        "        if paramLabel not in ['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', \n",
        "                              'lowHz_', 'bandHz_', 'weight', 'bias']:\n",
        "            continue\n",
        "        param = model\n",
        "        for i in range(len(paramName)):\n",
        "            param = getattr(param, paramName[i])\n",
        "        experiment.log_histogram_3d(param.cpu().detach().numpy(), name=\"%s/%s\" % (\"Parameters\", name), step=step)\n",
        "\n",
        "\n",
        "def trainingLoop(trainDataset,\n",
        "                 valDataset,\n",
        "                 batchSize,\n",
        "                 samplingMode,\n",
        "                 cpcModel,\n",
        "                 cpcCriterion,\n",
        "                 nEpoch,\n",
        "                 optimizer,\n",
        "                 pathCheckpoint,\n",
        "                 logs,\n",
        "                 useGPU,\n",
        "                 log2Board=0):\n",
        "    print(f\"Running {nEpoch} epochs\")\n",
        "    startEpoch = len(logs[\"epoch\"])\n",
        "    bestAcc = 0\n",
        "    bestStateDict = None\n",
        "    startTime = time.time()\n",
        "    epoch = 0\n",
        "    totalSteps = 0\n",
        "    try:\n",
        "        for epoch in range(startEpoch, nEpoch):\n",
        "            print(f\"Starting epoch {epoch}\")\n",
        "            trainLoader = trainDataset.getDataLoader(batchSize, samplingMode,\n",
        "                                                    True, numWorkers=0)\n",
        "            valLoader = valDataset.getDataLoader(batchSize, 'sequential', False,\n",
        "                                                numWorkers=0)\n",
        "\n",
        "            print(\"Training dataset %d batches, Validation dataset %d batches, batch size %d\" %\n",
        "                (len(trainLoader), len(valLoader), batchSize))\n",
        "\n",
        "            locLogsTrain = trainStep(trainLoader, cpcModel, cpcCriterion, optimizer, logs[\"logging_step\"], \n",
        "                                        useGPU, log2Board, totalSteps)\n",
        "\n",
        "            totalSteps += locLogsTrain['iter']\n",
        "\n",
        "            locLogsVal = valStep(valLoader, cpcModel, cpcCriterion, useGPU)\n",
        "\n",
        "            print(f'Ran {epoch + 1} epochs '\n",
        "                f'in {time.time() - startTime:.2f} seconds')\n",
        "\n",
        "            if useGPU:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            currentAccuracy = float(locLogsVal[\"locAcc_val\"].mean())\n",
        "            \n",
        "            if log2Board:\n",
        "                for t in range(len(locLogsVal[\"locLoss_val\"])):\n",
        "                    experiment.log_metric(f\"Losses/epoch/locLoss_train_{t}\", locLogsTrain[\"locLoss_train\"][t] / totalSteps, step=epoch)\n",
        "                    experiment.log_metric(f\"Accuracy/epoch/locAcc_train_{t}\", locLogsTrain[\"locAcc_train\"][t] / totalSteps, step=epoch)\n",
        "                    experiment.log_metric(f\"Losses/epoch/locLoss_val_{t}\", locLogsVal[\"locLoss_val\"][t] / totalSteps, step=epoch)\n",
        "                    experiment.log_metric(f\"Accuracy/epoch/locAcc_val_{t}\", locLogsVal[\"locAcc_val\"][t] / totalSteps, step=epoch)\n",
        "\n",
        "            if currentAccuracy > bestAcc:\n",
        "                bestStateDict = cpcModel.state_dict()\n",
        "\n",
        "            for key, value in dict(locLogsTrain, **locLogsVal).items():\n",
        "                if key not in logs:\n",
        "                    logs[key] = [None for _ in range(epoch)]\n",
        "                if isinstance(value, np.ndarray):\n",
        "                    value = value.tolist()\n",
        "                logs[key].append(value)\n",
        "\n",
        "            logs[\"epoch\"].append(epoch)\n",
        "\n",
        "            if pathCheckpoint is not None and (epoch % logs[\"saveStep\"] == 0 or epoch == nEpoch - 1):\n",
        "                modelStateDict = cpcModel.state_dict()\n",
        "                criterionStateDict = cpcCriterion.state_dict()\n",
        "\n",
        "                save_checkpoint(modelStateDict, criterionStateDict, optimizer.state_dict(), bestStateDict,\n",
        "                                f\"{pathCheckpoint}_{epoch}.pt\")\n",
        "                save_logs(logs, pathCheckpoint + \"_logs.json\")\n",
        "    except KeyboardInterrupt:\n",
        "        if pathCheckpoint is not None:\n",
        "            modelStateDict = cpcModel.state_dict()\n",
        "            criterionStateDict = cpcCriterion.state_dict()\n",
        "\n",
        "            save_checkpoint(modelStateDict, criterionStateDict, optimizer.state_dict(), bestStateDict,\n",
        "                            f\"{pathCheckpoint}_{epoch}_interrupted.pt\")\n",
        "            save_logs(logs, pathCheckpoint + \"_logs.json\")\n",
        "        return\n",
        "\n",
        "def run(trainDataset,\n",
        "        valDataset,\n",
        "        batchSize,\n",
        "        samplingMode,\n",
        "        cpcModel,\n",
        "        cpcCriterion,\n",
        "        nEpoch,\n",
        "        optimizer,\n",
        "        pathCheckpoint,\n",
        "        logs,\n",
        "        useGPU,\n",
        "        log2Board=0):\n",
        "    if log2Board:\n",
        "        with experiment.train():\n",
        "            trainingLoop(trainDataset, valDataset, batchSize, samplingMode, cpcModel, cpcCriterion, nEpoch, optimizer,\n",
        "                         pathCheckpoint, logs, useGPU, log2Board)\n",
        "            experiment.end()\n",
        "    else:\n",
        "        trainingLoop(trainDataset, valDataset, batchSize, samplingMode, cpcModel, cpcCriterion, nEpoch, optimizer, \n",
        "                     pathCheckpoint, logs, useGPU, log2Board)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1undhM04n55"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpthiUBiVZ_W"
      },
      "source": [
        "import torch\n",
        "# from dataloader import AudioBatchData\n",
        "# from model import CPCEncoder, CPCAR, CPCModel, CPCUnsupersivedCriterion\n",
        "# from trainer import run\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1IN1MRVdDy",
        "outputId": "8d9fbc92-441d-48b8-9f1e-5121f518d46a"
      },
      "source": [
        "useGPU = torch.cuda.is_available()\n",
        "labelsBy = 'ensemble'\n",
        "print(\"Loading the training dataset\")\n",
        "trainDataset = AudioBatchData(rawAudioPath='data/musicnet_lousy/train_data',\n",
        "                                metadataPath='data/musicnet_lousy/metadata_train.csv',\n",
        "                                sizeWindow=20480,\n",
        "                                labelsBy=labelsBy,\n",
        "                                outputPath='data/musicnet_lousy/train_data/train',\n",
        "                                CHUNK_SIZE=1e9,\n",
        "                                NUM_CHUNKS_INMEM=7,\n",
        "                                useGPU=useGPU)\n",
        "print(\"Training dataset loaded\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"Loading the validation dataset\")\n",
        "valDataset = AudioBatchData(rawAudioPath='data/musicnet_lousy/train_data',\n",
        "                            metadataPath='data/musicnet_lousy/metadata_val.csv',\n",
        "                            sizeWindow=20480,\n",
        "                            labelsBy=labelsBy,\n",
        "                            outputPath='data/musicnet_lousy/train_data/val',\n",
        "                            CHUNK_SIZE=1e9,\n",
        "                            NUM_CHUNKS_INMEM=1,\n",
        "                            useGPU=False)\n",
        "print(\"Validation dataset loaded\")\n",
        "print(\"\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the training dataset\n",
            "Chunks already exist at data/musicnet_lousy/train_data/train/ensemble\n",
            "Loading files\n",
            "Loaded 288 sequences, elapsed=143.175 secs\n",
            "Training dataset loaded\n",
            "\n",
            "Loading the validation dataset\n",
            "Chunks already exist at data/musicnet_lousy/train_data/val/ensemble\n",
            "Loading files\n",
            "Loaded 32 sequences, elapsed=20.344 secs\n",
            "Validation dataset loaded\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBri49jRXtf0",
        "outputId": "49f38177-a9e3-4cd3-9a66-5cecebf525d6"
      },
      "source": [
        "useTransformer = True\n",
        "samplingType = 'samesequence'\n",
        "\n",
        "# Encoder network\n",
        "encoderNet = CPCEncoder(512, 'layerNorm', sincNet=True)\n",
        "# AR Network\n",
        "if useTransformer:\n",
        "    arNet = buildTransformerAR(512, 1, 20480 // 160, abspos=False)\n",
        "    hiddenGAr = 512\n",
        "else:\n",
        "    arNet = CPCAR(512, 256, samplingType == 'sequential', 1, mode=\"GRU\", reverse=False)\n",
        "    hiddenGAr = 256\n",
        "\n",
        "cpcModel = CPCModel(encoderNet, arNet)\n",
        "batchSize = 8\n",
        "cpcModel.supervised = False\n",
        "\n",
        "cpcCriterion = CPCUnsupersivedCriterion(nPredicts=12,\n",
        "                                        dimOutputAR=hiddenGAr,\n",
        "                                        dimOutputEncoder=512,\n",
        "                                        negativeSamplingExt=128,\n",
        "                                        mode=None,\n",
        "                                        dropout=False)\n",
        "\n",
        "if useGPU:\n",
        "    cpcCriterion.cuda()\n",
        "    cpcModel.cuda()\n",
        "\n",
        "gParams = list(cpcCriterion.parameters()) + list(cpcModel.parameters())\n",
        "lr = 2e-4\n",
        "optimizer = torch.optim.Adam(gParams, lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "expDescription = f'{samplingType}_'\n",
        "if samplingType == 'samecategory':\n",
        "    expDescription += f'{labelsBy}_'\n",
        "\n",
        "pathCheckpoint = f'logs/{expDescription}{datetime.now().strftime(\"%d-%m_%H-%M-%S\")}'\n",
        "os.makedirs(pathCheckpoint, exist_ok=True)\n",
        "pathCheckpoint = os.path.join(pathCheckpoint, \"checkpoint\")\n",
        "\n",
        "logs = {\"epoch\": [], \"iter\": [], \"saveStep\": 1, \"logging_step\": 1000}\n",
        "\n",
        "run(trainDataset, valDataset, batchSize, samplingType, cpcModel, cpcCriterion, 30, optimizer, pathCheckpoint, logs, \n",
        "    useGPU, log2Board=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running 30 epochs\n",
            "Starting epoch 0\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 308.9 s\n",
            "308.9 ms per batch, 38.6 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         2.309381         3.001758         4.006115         4.108611         4.169734         4.198469         4.168210         4.172213         4.228028         4.306034         4.381202         4.461448\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.631744         0.328276         0.136016         0.124933         0.117415         0.113673         0.116272         0.116558         0.107460         0.093513         0.083485         0.070186\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 310.0 s\n",
            "310.0 ms per batch, 38.8 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.760358         1.426994         3.023254         3.348082         3.554146         3.641985         3.658018         3.725305         3.847096         3.952634         4.062529         4.182001\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.921784         0.677644         0.283428         0.225038         0.195191         0.184907         0.186513         0.177379         0.152355         0.134323         0.115623         0.096466\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 310.8 s\n",
            "310.8 ms per batch, 38.8 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.410249         0.809572         2.317535         2.685912         3.001992         3.209394         3.349135         3.489010         3.621653         3.730602         3.843869         3.964194\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.969197         0.831463         0.427209         0.353748         0.298131         0.259653         0.237026         0.210281         0.182825         0.163378         0.143280         0.124065\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 311.6 s\n",
            "311.6 ms per batch, 38.9 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.270617         0.525678         1.848041         2.209173         2.548359         2.813475         3.007100         3.196134         3.356733         3.485198         3.612544         3.743023\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.981398         0.897536         0.536945         0.464988         0.400153         0.347665         0.311168         0.272443         0.237658         0.211558         0.186235         0.161722\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 310.9 s\n",
            "310.9 ms per batch, 38.9 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.209494         0.391305         1.507049         1.849878         2.187930         2.473765         2.696312         2.909328         3.082291         3.238360         3.383615         3.525614\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.987642         0.929151         0.621880         0.552705         0.486577         0.429098         0.385404         0.339603         0.301838         0.267074         0.237067         0.209138\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 312.9 s\n",
            "312.9 ms per batch, 39.1 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.174038         0.308936         1.264674         1.580777         1.904238         2.196097         2.444276         2.677662         2.862555         3.032286         3.186263         3.335396\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.991239         0.948740         0.682798         0.617157         0.551506         0.490533         0.439904         0.390746         0.351161         0.313992         0.280395         0.250366\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 313.3 s\n",
            "313.3 ms per batch, 39.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.151844         0.254358         1.084983         1.363753         1.672004         1.969565         2.247875         2.487578         2.680421         2.865239         3.032036         3.187108\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.993445         0.962268         0.730520         0.672048         0.606609         0.542317         0.482889         0.432473         0.389923         0.347789         0.311020         0.277954\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 312.9 s\n",
            "312.9 ms per batch, 39.1 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.136200         0.214920         0.938550         1.198462         1.490289         1.779657         2.065710         2.307504         2.507696         2.703634         2.882175         3.045078\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.994888         0.971570         0.767120         0.711087         0.649017         0.585389         0.521852         0.470227         0.426680         0.380641         0.339748         0.305239\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 314.1 s\n",
            "314.1 ms per batch, 39.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.140313         0.211926         0.967158         1.280211         1.620452         1.914055         2.194930         2.429870         2.626854         2.810137         2.972996         3.121395\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.994363         0.973083         0.753834         0.684133         0.613075         0.548156         0.485885         0.435814         0.392417         0.350200         0.311045         0.280534\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 313.8 s\n",
            "313.8 ms per batch, 39.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.136514         0.201290         0.925557         1.254770         1.608002         1.894457         2.166359         2.398259         2.589882         2.760327         2.914663         3.060902\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.994798         0.975842         0.761711         0.685644         0.610290         0.546794         0.485296         0.434560         0.392461         0.352710         0.316487         0.286218\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.454948         0.710505         1.748075         2.049337         2.340577         2.576583         2.771182         2.953299         3.115816         3.264998         3.404223         3.539980\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.948197         0.855229         0.579100         0.517218         0.459698         0.410903         0.370213         0.332343         0.297466         0.265232         0.235874         0.209454\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.125331         0.172686         0.766132         1.062061         1.368181         1.636478         1.893755         2.128850         2.329736         2.508992         2.660740         2.803873\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.993916         0.978608         0.801230         0.728725         0.656824         0.594113         0.531494         0.476400         0.429027         0.384503         0.345293         0.312400\n",
            "--------------------------------------------------\n",
            "Ran 1 epochs in 3354.93 seconds\n",
            "Starting epoch 1\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 312.0 s\n",
            "312.0 ms per batch, 39.0 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.105268         0.150502         0.739430         1.011194         1.303765         1.574383         1.834878         2.068037         2.276117         2.457254         2.619543         2.788042\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.998037         0.984765         0.810019         0.742832         0.674280         0.609591         0.548480         0.495075         0.446502         0.405526         0.367329         0.329692\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 315.7 s\n",
            "315.7 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.110577         0.155767         0.742130         1.043368         1.368642         1.664970         1.950900         2.211287         2.433494         2.630805         2.807774         2.971665\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996987         0.983501         0.806679         0.731425         0.654343         0.583591         0.516144         0.457976         0.408999         0.365200         0.325339         0.291551\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 315.1 s\n",
            "315.1 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.118495         0.165466         0.743735         1.061802         1.411497         1.733714         2.036844         2.312709         2.542882         2.735434         2.901029         3.056873\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.995060         0.980945         0.805801         0.724384         0.637103         0.559199         0.487149         0.423449         0.372956         0.330249         0.292148         0.260151\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 315.5 s\n",
            "315.5 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.115835         0.157502         0.675379         0.965435         1.283032         1.591196         1.880915         2.152775         2.385322         2.581689         2.754240         2.917462\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.995149         0.982045         0.825477         0.751663         0.672353         0.597404         0.528513         0.465661         0.412758         0.369645         0.330449         0.295150\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 315.7 s\n",
            "315.7 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.116190         0.157304         0.672918         0.964579         1.275498         1.569288         1.844561         2.103937         2.328163         2.522705         2.696006         2.859809\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.995309         0.982059         0.826814         0.754706         0.679317         0.608860         0.544405         0.484712         0.435328         0.391388         0.351595         0.317638\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 315.4 s\n",
            "315.4 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.112173         0.146848         0.593663         0.845902         1.114805         1.390715         1.659093         1.915200         2.144359         2.347948         2.533963         2.705490\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996445         0.985169         0.852329         0.790036         0.723909         0.657288         0.593143         0.533797         0.482171         0.435575         0.392528         0.356053\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 315.3 s\n",
            "315.3 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.106985         0.138476         0.559305         0.803153         1.064200         1.329587         1.589455         1.837319         2.061818         2.264612         2.453772         2.625330\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997292         0.987426         0.862100         0.802403         0.738904         0.674939         0.611968         0.554610         0.503300         0.456704         0.412625         0.375642\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 315.4 s\n",
            "315.4 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.106554         0.137827         0.561301         0.810964         1.077325         1.342788         1.599782         1.845080         2.068827         2.270421         2.458658         2.629033\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997462         0.987515         0.861346         0.798996         0.734158         0.670584         0.609529         0.551787         0.500228         0.454220         0.409949         0.372902\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 315.5 s\n",
            "315.5 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.111788         0.146030         0.582358         0.852226         1.131716         1.400879         1.653463         1.890052         2.105446         2.298215         2.475237         2.635883\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996666         0.985980         0.853115         0.784515         0.716427         0.652380         0.591783         0.536304         0.486806         0.442957         0.400220         0.365390\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 316.2 s\n",
            "316.2 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.113736         0.150495         0.607920         0.898302         1.203018         1.483549         1.745731         1.985219         2.204502         2.392721         2.566379         2.718099\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.995944         0.984202         0.843675         0.768100         0.691462         0.623048         0.560050         0.504040         0.453944         0.411676         0.371048         0.338989\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.111836         0.150439         0.645136         0.923025         1.220322         1.504608         1.775504         2.027166         2.249814         2.444450         2.620812         2.784473\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996426         0.984408         0.835379         0.765463         0.692712         0.624242         0.559733         0.501502         0.451057         0.407104         0.366176         0.331224\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.115623         0.145969         0.540590         0.803524         1.064362         1.310824         1.545391         1.765463         1.965879         2.133976         2.295072         2.436237\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.995178         0.984691         0.860328         0.789684         0.721186         0.658247         0.597604         0.541961         0.491243         0.449825         0.407767         0.374298\n",
            "--------------------------------------------------\n",
            "Ran 2 epochs in 6745.02 seconds\n",
            "Starting epoch 2\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 313.0 s\n",
            "313.0 ms per batch, 39.1 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.094363         0.116350         0.481726         0.709039         0.955208         1.204202         1.432871         1.651312         1.861752         2.042562         2.214569         2.382249\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.998609         0.991484         0.879364         0.819176         0.755934         0.692276         0.636106         0.581471         0.529772         0.486376         0.444481         0.404361\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 315.7 s\n",
            "315.7 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.098194         0.124542         0.522214         0.781384         1.058414         1.339118         1.604256         1.852876         2.080074         2.285378         2.473994         2.645220\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.998072         0.989676         0.865815         0.796611         0.725982         0.654926         0.588525         0.529170         0.475431         0.428083         0.383692         0.346391\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 315.9 s\n",
            "315.9 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.108060         0.135944         0.553389         0.839718         1.150462         1.456368         1.742945         2.006355         2.244287         2.454083         2.636089         2.798743\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996220         0.987361         0.858191         0.782252         0.701351         0.623970         0.552373         0.489095         0.432370         0.383409         0.340746         0.305360\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 316.0 s\n",
            "316.0 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.104700         0.131453         0.516434         0.791544         1.086190         1.378199         1.655577         1.910844         2.144003         2.349134         2.535900         2.704923\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996574         0.987559         0.868209         0.796177         0.720626         0.647805         0.578391         0.516793         0.461269         0.413064         0.368944         0.332112\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 316.1 s\n",
            "316.1 ms per batch, 39.5 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.104598         0.129523         0.488364         0.736107         0.998756         1.271035         1.533324         1.776566         2.003219         2.209006         2.401056         2.569829\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.996812         0.988711         0.878404         0.813974         0.747153         0.678411         0.613025         0.553652         0.498873         0.450350         0.404609         0.366769\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 314.6 s\n",
            "314.6 ms per batch, 39.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.104680         0.127732         0.469644         0.702418         0.946947         1.202870         1.450647         1.684056         1.906753         2.109562         2.300140         2.471737\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997586         0.989994         0.885185         0.825262         0.762930         0.698836         0.636154         0.579402         0.525923         0.477920         0.431713         0.394210\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 314.6 s\n",
            "314.6 ms per batch, 39.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.102289         0.123073         0.443427         0.662077         0.893573         1.139012         1.383876         1.613841         1.837903         2.042892         2.237460         2.410534\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997607         0.990503         0.892544         0.836278         0.777339         0.714652         0.653501         0.597528         0.544333         0.495348         0.448984         0.409572\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 315.1 s\n",
            "315.1 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.103656         0.125864         0.446311         0.658910         0.882960         1.118183         1.352680         1.576577         1.792929         1.993379         2.186220         2.356473\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997956         0.990754         0.893211         0.839075         0.782157         0.723183         0.665239         0.610755         0.559704         0.512060         0.465811         0.427793\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 315.4 s\n",
            "315.4 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.102546         0.126907         0.484429         0.735167         0.992254         1.247669         1.496456         1.723002         1.938757         2.132199         2.318151         2.483193\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997792         0.989746         0.879746         0.813641         0.748255         0.684612         0.623377         0.569497         0.517921         0.471724         0.428797         0.391082\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 314.5 s\n",
            "314.5 ms per batch, 39.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.104613         0.128374         0.494350         0.764097         1.042342         1.304952         1.555190         1.777149         1.989759         2.177557         2.359601         2.516275\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997888         0.989953         0.875795         0.802384         0.729699         0.663414         0.601175         0.547401         0.497106         0.453220         0.409852         0.375187\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.102747         0.126831         0.489733         0.738872         1.002372         1.267754         1.522313         1.758207         1.980377         2.179517         2.366136         2.533130\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.997524         0.989630         0.877698         0.812134         0.744492         0.677570         0.614138         0.556937         0.503867         0.456873         0.412529         0.375211\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.106195         0.125463         0.449715         0.696538         0.940653         1.177694         1.411437         1.620378         1.820496         1.992156         2.161402         2.305058\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.997486         0.990109         0.886999         0.819967         0.755803         0.693891         0.634439         0.581063         0.530539         0.487782         0.443434         0.407893\n",
            "--------------------------------------------------\n",
            "Ran 3 epochs in 10133.16 seconds\n",
            "Starting epoch 3\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 311.7 s\n",
            "311.7 ms per batch, 39.0 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.091475         0.106340         0.396233         0.604249         0.827049         1.062957         1.286675         1.496349         1.706203         1.890898         2.067153         2.238433\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.999234         0.994598         0.903695         0.846640         0.788072         0.726268         0.669712         0.616730         0.564212         0.519307         0.475242         0.435074\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 315.3 s\n",
            "315.3 ms per batch, 39.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.095086         0.113320         0.435127         0.675802         0.930619         1.201786         1.461959         1.706012         1.934145         2.141828         2.337021         2.510117\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.998687         0.992897         0.891430         0.824885         0.758369         0.687740         0.622066         0.561969         0.506950         0.457958         0.412390         0.373908\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5WYUmPQExz4"
      },
      "source": [
        "# gru = nn.GRU(512, 256, num_layers=1, batch_first=True)\n",
        "# sizeHidden = 512\n",
        "# sinc0 = SincConv1D(1, sizeHidden, 10, stride=5, padding=3)\n",
        "# conv0 = nn.Conv1d(1, sizeHidden, 10, stride=5, padding=3)\n",
        "# batchNorm0 = ChannelNorm(sizeHidden)\n",
        "# reluLayer = nn.LeakyReLU(0.1)\n",
        "# print(\"GRU\")\n",
        "# for name, param in gru.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(\"Sinc\")\n",
        "# for name, param in sinc0.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(\"Conv\")\n",
        "# for name, param in conv0.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(\"BatchNorm\")\n",
        "# for name, param in batchNorm0.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(\"Transformer\")\n",
        "# for name, param in arNet.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(\"ReLU\")\n",
        "# for name, param in reluLayer.named_parameters():\n",
        "#     print(\"\\t\", name)\n",
        "#     print(\"\\t\", name.split('.')[-1])\n",
        "# print(len(list(reluLayer.named_parameters())))"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}