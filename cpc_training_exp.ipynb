{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cpc_training_exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS3zre3hVRaa",
        "outputId": "c42ec43c-6bc2-4866-b2ab-4bbc7e58c642"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/DLProjects/JTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/DLProjects/JTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmv_AG1ws6Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc021a6-1380-4c52-c018-848bfad6fdaa"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-09de49a6-5eda-70f3-f4ab-5bdfd6e8ff96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4W0oTBeW8q_",
        "outputId": "696862f9-65d4-4200-f554-bcba2df3f63d"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.15.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.0.1)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.1.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.0.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (1.12.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.20.22)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from comet_ml) (0.9.1)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet_ml) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0Ie8ZO5TVd",
        "outputId": "2de29566-2af5-4905-bf90-c27b2e1b7779"
      },
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=\"K5CvVquVZJNg9xfY2ip95FuoD\",\n",
        "    project_name=\"jtm\",\n",
        "    workspace=\"tiagocuervo\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/tiagocuervo/jtm/d6628cdb2fb647e8b5cf2219581ef8dd\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0pN8vB4qV6"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w4ZEQ4r4s5p"
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import Sampler, BatchSampler\n",
        "import librosa\n",
        "import tqdm\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AudioBatchData(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 rawAudioPath,\n",
        "                 metadataPath,\n",
        "                 sizeWindow,\n",
        "                 labelsBy='composer',\n",
        "                 outputPath=None,\n",
        "                 CHUNK_SIZE=1e9,\n",
        "                 NUM_CHUNKS_INMEM=2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            - rawAudioPath (string): path to the raw audio files\n",
        "            - metadataPath (string): path to the data set metadata (used to define labels)\n",
        "            - sizeWindow (int): size of the sliding window\n",
        "            - labelsBy (string): name of column in metadata according to which create labels\n",
        "            - outputPath (string): path to the directory where chunks are to be created or are stored\n",
        "            - CHUNK_SIZE (int): desired size in bytes of a chunk\n",
        "            - NUM_CHUNKS_INMEM (int): target maximal size chunks of data to load in memory at a time\n",
        "        \"\"\"\n",
        "        self.NUM_CHUNKS_INMEM = NUM_CHUNKS_INMEM\n",
        "        self.CHUNK_SIZE = CHUNK_SIZE\n",
        "        self.rawAudioPath = Path(rawAudioPath)\n",
        "        self.sizeWindow = sizeWindow\n",
        "\n",
        "        self.sequencesData = pd.read_csv(metadataPath, index_col='id')\n",
        "        self.sequencesData = self.sequencesData.sort_values(by=labelsBy)\n",
        "        self.sequencesData[labelsBy] = self.sequencesData[labelsBy].astype('category')\n",
        "        self.sequencesData[labelsBy] = self.sequencesData[labelsBy].cat.codes\n",
        "\n",
        "        self.totSize = self.sequencesData['length'].sum()\n",
        "        # print(\"Total size:\", self.totSize)\n",
        "        # print(\"Length of data set:\", self.__len__())\n",
        "\n",
        "        self.category = labelsBy\n",
        "\n",
        "        if outputPath is None:\n",
        "            self.chunksDir = self.rawAudioPath / labelsBy\n",
        "        else:\n",
        "            self.chunksDir = Path(outputPath) / labelsBy\n",
        "\n",
        "        if not os.path.exists(self.chunksDir):\n",
        "            os.makedirs(self.chunksDir)\n",
        "\n",
        "        packages2Load = [fileName for fileName in os.listdir(self.chunksDir) if\n",
        "                         re.match(r'chunk_.*[0-9]+.pickle', fileName)]\n",
        "\n",
        "        if len(packages2Load) == 0:\n",
        "            self._createChunks()\n",
        "            packages2Load = [fileName for fileName in os.listdir(self.chunksDir) if\n",
        "                             re.match(r'chunk_.*[0-9]+.pickle', fileName)]\n",
        "        else:\n",
        "            print(\"Chunks already exist at\", self.chunksDir)\n",
        "\n",
        "        self.packs = []\n",
        "        packOfChunks = []\n",
        "        for i, packagePath in enumerate(packages2Load):\n",
        "            packOfChunks.append(packagePath)\n",
        "            if (i + 1) % self.NUM_CHUNKS_INMEM == 0:\n",
        "                self.packs.append(packOfChunks)\n",
        "                packOfChunks = []\n",
        "        if len(packOfChunks) > 0:\n",
        "            self.packs.append(packOfChunks)\n",
        "\n",
        "        self.currentPack = -1\n",
        "        self.nextPack = 0\n",
        "        self.sequenceIdx = 0\n",
        "\n",
        "        self.data = None\n",
        "\n",
        "        self._loadNextPack(first=True)\n",
        "        self._loadNextPack()\n",
        "\n",
        "    def _createChunks(self):\n",
        "        print(\"Creating chunks at\", self.chunksDir)\n",
        "        pack = []\n",
        "        packIds = []\n",
        "        packageSize = 0\n",
        "        packageIdx = 0\n",
        "        for trackId in tqdm.tqdm(self.sequencesData.index):\n",
        "            sequence, samplingRate = librosa.load(self.rawAudioPath / (str(trackId) + '.wav'), sr=16000)\n",
        "            sequence = torch.tensor(sequence).float()\n",
        "            packIds.append(trackId)\n",
        "            pack.append(sequence)\n",
        "            packageSize += len(sequence) * 4\n",
        "            if packageSize >= self.CHUNK_SIZE:\n",
        "                print(f\"Saved pack {packageIdx}\")\n",
        "                with open(self.chunksDir / f'chunk_{packageIdx}.pickle', 'wb') as handle:\n",
        "                    pickle.dump(torch.cat(pack, dim=0), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "                with open(self.chunksDir / f'ids_{packageIdx}.pickle', 'wb') as handle:\n",
        "                    pickle.dump(packIds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "                pack = []\n",
        "                packIds = []\n",
        "                packageSize = 0\n",
        "                packageIdx += 1\n",
        "        print(f\"Saved pack {packageIdx}\")\n",
        "        with open(self.chunksDir / f'chunk_{packageIdx}.pickle', 'wb') as handle:\n",
        "            pickle.dump(torch.cat(pack, dim=0), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        with open(self.chunksDir / f'ids_{packageIdx}.pickle', 'wb') as handle:\n",
        "            pickle.dump(packIds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def _loadNextPack(self, first=False):\n",
        "        self.clear()\n",
        "        if not first:\n",
        "            self.currentPack = self.nextPack\n",
        "            startTime = time.time()\n",
        "            print('Loading files')\n",
        "            self.categoryLabel = [0]\n",
        "            packageIdx = [0]\n",
        "            self.seqLabel = [0]\n",
        "            packageSize = 0\n",
        "            previousCategory = 0\n",
        "            for packagePath in self.packs[self.currentPack]:\n",
        "                with open(self.chunksDir / ('ids_' + packagePath.split('_', maxsplit=1)[-1]), 'rb') as handle:\n",
        "                    chunkIds = pickle.load(handle)\n",
        "                for seqId in chunkIds:\n",
        "                    currentCategory = self.sequencesData.loc[seqId][self.category]\n",
        "                    if currentCategory != previousCategory:\n",
        "                        self.categoryLabel.append(packageSize)\n",
        "                    previousCategory = currentCategory\n",
        "                    packageSize += self.sequencesData.loc[seqId].length\n",
        "                    self.seqLabel.append(packageSize)\n",
        "                packageIdx.append(packageSize)\n",
        "\n",
        "            self.data = torch.empty(size=(packageSize,))\n",
        "            for i, packagePath in enumerate(self.packs[self.currentPack]):\n",
        "                with open(self.chunksDir / packagePath, 'rb') as handle:\n",
        "                    self.data[packageIdx[i]:packageIdx[i + 1]] = pickle.load(handle)\n",
        "            print(f'Loaded {len(self.seqLabel) - 1} sequences, elapsed={time.time() - startTime:.3f} secs')\n",
        "\n",
        "        self.nextPack = (self.currentPack + 1) % len(self.packs)\n",
        "        if self.nextPack == 0 and len(self.packs) > 1:\n",
        "            self.currentPack = -1\n",
        "            self.nextPack = 0\n",
        "            self.sequenceIdx = 0\n",
        "\n",
        "    def clear(self):\n",
        "        if 'data' in self.__dict__:\n",
        "            del self.data\n",
        "        if 'categoryLabel' in self.__dict__:\n",
        "            del self.categoryLabel\n",
        "        if 'seqLabel' in self.__dict__:\n",
        "            del self.seqLabel\n",
        "\n",
        "    def getCategoryLabel(self, idx):\n",
        "        idCategory = next(x[0] for x in enumerate(self.categoryLabel) if x[1] > idx) - 1\n",
        "        return idCategory\n",
        "\n",
        "    def getSequenceLabel(self, idx):\n",
        "        return self.categoryLabel[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.totSize // self.sizeWindow\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < 0 or idx >= len(self.data) - self.sizeWindow - 1:\n",
        "            print(idx)\n",
        "\n",
        "        outData = self.data[idx:(self.sizeWindow + idx)].view(1, -1)\n",
        "        label = torch.tensor(self.getCategoryLabel(idx), dtype=torch.long)\n",
        "        return outData, label\n",
        "\n",
        "    def getBaseSampler(self, samplingType, batchSize, offset):\n",
        "        if samplingType == \"samecategory\":\n",
        "            return SameTrackSampler(batchSize, self.categoryLabel, self.sizeWindow, offset)\n",
        "        if samplingType == \"samesequence\":\n",
        "            return SameTrackSampler(batchSize, self.seqLabel, self.sizeWindow, offset)\n",
        "        if samplingType == \"sequential\":\n",
        "            return SequentialSampler(len(self.data), self.sizeWindow, offset, batchSize)\n",
        "\n",
        "        sampler = UniformAudioSampler(len(self.data), self.sizeWindow, offset)\n",
        "        return BatchSampler(sampler, batchSize, True)\n",
        "\n",
        "    def getDataLoader(self, batchSize, samplingType, randomOffset, numWorkers=0,\n",
        "                      onLoop=-1):\n",
        "        r\"\"\"\n",
        "        Get a batch sampler for the current dataset.\n",
        "            - batchSize (int): batch size\n",
        "            - groupSize (int): in the case of type in [\"track\", \"sequence\"]\n",
        "            number of items sharing a same label in the group\n",
        "            (see AudioBatchSampler)\n",
        "            - type (string):\n",
        "                type == \"track\": grouped sampler track-wise\n",
        "                type == \"sequence\": grouped sampler sequence-wise\n",
        "                type == \"sequential\": sequential sampling\n",
        "                else: uniform random sampling of the full audio\n",
        "                vector\n",
        "            - randomOffset (bool): if True add a random offset to the sampler\n",
        "                                   at the begining of each iteration\n",
        "        \"\"\"\n",
        "        nLoops = len(self.packs)\n",
        "        totSize = self.totSize // (self.sizeWindow * batchSize)\n",
        "        if onLoop >= 0:\n",
        "            self.currentPack = onLoop - 1\n",
        "            self._loadNextPack()\n",
        "            nLoops = 1\n",
        "\n",
        "        def samplerCall():\n",
        "            offset = random.randint(0, self.sizeWindow // 2) \\\n",
        "                if randomOffset else 0\n",
        "            return self.getBaseSampler(samplingType, batchSize, offset)\n",
        "\n",
        "        return AudioLoader(self, samplerCall, nLoops, self._loadNextPack, totSize, numWorkers)\n",
        "\n",
        "\n",
        "class AudioLoader(object):\n",
        "    r\"\"\"\n",
        "    A DataLoader meant to handle an AudioBatchData object.\n",
        "    In order to handle big datasets AudioBatchData works with big chunks of\n",
        "    audio it loads sequentially in memory: once all batches have been sampled\n",
        "    on a chunk, the AudioBatchData loads the next one.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataset,\n",
        "                 samplerCall,\n",
        "                 nLoop,\n",
        "                 updateCall,\n",
        "                 size,\n",
        "                 numWorkers):\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            - dataset (AudioBatchData): target dataset\n",
        "            - samplerCall (function): batch-sampler to call\n",
        "            - nLoop (int): number of chunks to load\n",
        "            - updateCall (function): function loading the next chunk\n",
        "            - size (int): total number of batches\n",
        "            - numWorkers (int): see torch.utils.data.DataLoader\n",
        "        \"\"\"\n",
        "        self.samplerCall = samplerCall\n",
        "        self.updateCall = updateCall\n",
        "        self.nLoop = nLoop\n",
        "        self.size = size\n",
        "        self.dataset = dataset\n",
        "        self.numWorkers = numWorkers\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        for i in range(self.nLoop):\n",
        "            sampler = self.samplerCall()\n",
        "            dataloader = DataLoader(self.dataset,\n",
        "                                    batch_sampler=sampler,\n",
        "                                    num_workers=self.numWorkers)\n",
        "            # print(\"Data loader nLoop: \", self.nLoop)\n",
        "            # print(\"Len data loader: \", len(dataloader))\n",
        "            # print(\"Len of sampler: \", len(sampler))\n",
        "            # assert False\n",
        "            # print(\"Dataloader len: \\n\", len(dataloader))\n",
        "            for j, x in enumerate(dataloader):\n",
        "                # print(\"Data loader yielded batch #: \", j)\n",
        "                yield x\n",
        "            # print(\"Len data loader: \", len(dataloader), \"and consummed: \", j + 1)\n",
        "            if i < self.nLoop - 1:\n",
        "                self.updateCall()\n",
        "\n",
        "\n",
        "class UniformAudioSampler(Sampler):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataSize,\n",
        "                 sizeWindow,\n",
        "                 offset):\n",
        "        self.len = dataSize // sizeWindow\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.offset = offset\n",
        "        if self.offset > 0:\n",
        "            self.len -= 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter((self.offset\n",
        "                     + self.sizeWindow * torch.randperm(self.len)).tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "class SequentialSampler(Sampler):\n",
        "\n",
        "    def __init__(self, dataSize, sizeWindow, offset, batchSize):\n",
        "\n",
        "        self.len = (dataSize // sizeWindow) // batchSize\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.offset = offset\n",
        "        self.startBatches = [x * (dataSize // batchSize)\n",
        "                             for x in range(batchSize)]\n",
        "        self.batchSize = batchSize\n",
        "        if self.offset > 0:\n",
        "            self.len -= 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in range(self.len):\n",
        "            yield [self.offset + self.sizeWindow * idx\n",
        "                   + start for start in self.startBatches]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "class SameTrackSampler(Sampler):\n",
        "\n",
        "    def __init__(self,\n",
        "                 batchSize,\n",
        "                 samplingIntervals,\n",
        "                 sizeWindow,\n",
        "                 offset):\n",
        "\n",
        "        self.samplingIntervals = samplingIntervals\n",
        "        self.sizeWindow = sizeWindow\n",
        "        self.batchSize = batchSize\n",
        "        self.offset = offset\n",
        "\n",
        "        if self.samplingIntervals[0] != 0:\n",
        "            raise AttributeError(\"Sampling intervals should start at zero\")\n",
        "\n",
        "        nWindows = len(self.samplingIntervals) - 1\n",
        "        self.sizeSamplers = [(self.samplingIntervals[i + 1] -\n",
        "                              self.samplingIntervals[i]) // self.sizeWindow\n",
        "                             for i in range(nWindows)]  # How many windows a sequence/category lasts \n",
        "\n",
        "        # assert False\n",
        "        if self.offset > 0:\n",
        "            self.sizeSamplers = [max(0, x - 1) for x in self.sizeSamplers]\n",
        "        # print(\"Size samplers:\\n\", self.sizeSamplers)\n",
        "        # print(\"Size samplers over batch size:\\n\", np.array(self.sizeSamplers) // self.batchSize)\n",
        "\n",
        "        order = [(x, torch.randperm(val).tolist())\n",
        "                 for x, val in enumerate(self.sizeSamplers) if\n",
        "                 val > 0]  # (index of seq/cat, randomly permuted numbers from 0 to num windows in seq(cat))\n",
        "\n",
        "        # Build Batches\n",
        "        self.batches = []\n",
        "        for indexSampler, randperm in order:\n",
        "            indexStart, sizeSampler = 0, self.sizeSamplers[indexSampler]\n",
        "            while indexStart < (sizeSampler - self.batchSize):\n",
        "                indexEnd = indexStart + self.batchSize\n",
        "                locBatch = [self.getIndex(x, indexSampler)\n",
        "                            for x in randperm[indexStart:indexEnd]]\n",
        "                indexStart = indexEnd\n",
        "                self.batches.append(locBatch)\n",
        "        # print(\"Number of batches:\\n\", len(self.batches))\n",
        "        # print(\"Batches:\\n\", self.batches)\n",
        "        # print(\"Batches shape: \\n\", np.array(self.batches).shape)\n",
        "        # print(\"Batches vstack shape: \\n\", np.vstack(self.batches).shape)\n",
        "        self.batches = np.vstack(self.batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batches)\n",
        "\n",
        "    def getIndex(self, x, iInterval):\n",
        "        return self.offset + x * self.sizeWindow + self.samplingIntervals[iInterval]\n",
        "\n",
        "    def __iter__(self):\n",
        "        random.shuffle(self.batches)\n",
        "        return iter(self.batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMMWgc3M4xln"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbjSx6SH4yo1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ChannelNorm(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 numFeatures,\n",
        "                 epsilon=1e-05,\n",
        "                 affine=True):\n",
        "\n",
        "        super(ChannelNorm, self).__init__()\n",
        "        if affine:\n",
        "            self.weight = nn.parameter.Parameter(torch.Tensor(1,\n",
        "                                                              numFeatures, 1))\n",
        "            self.bias = nn.parameter.Parameter(torch.Tensor(1, numFeatures, 1))\n",
        "        else:\n",
        "            self.weight = None\n",
        "            self.bias = None\n",
        "        self.epsilon = epsilon\n",
        "        self.p = 0\n",
        "        self.affine = affine\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.affine:\n",
        "            torch.nn.init.ones_(self.weight)\n",
        "            torch.nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        cumMean = x.mean(dim=1, keepdim=True)\n",
        "        cumVar = x.var(dim=1, keepdim=True)\n",
        "        x = (x - cumMean) * torch.rsqrt(cumVar + self.epsilon)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            x = x * self.weight + self.bias\n",
        "        return x\n",
        "\n",
        "\n",
        "class CPCEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 sizeHidden=512,\n",
        "                 normMode=\"layerNorm\"):\n",
        "\n",
        "        super(CPCEncoder, self).__init__()\n",
        "\n",
        "        validModes = [\"batchNorm\", \"instanceNorm\", \"ID\", \"layerNorm\"]\n",
        "        if normMode not in validModes:\n",
        "            raise ValueError(f\"Norm mode must be in {validModes}\")\n",
        "\n",
        "        if normMode == \"instanceNorm\":\n",
        "            def normLayer(x):\n",
        "                return nn.InstanceNorm1d(x, affine=True)\n",
        "        elif normMode == \"layerNorm\":\n",
        "            normLayer = ChannelNorm\n",
        "        else:\n",
        "            normLayer = nn.BatchNorm1d\n",
        "\n",
        "        self.dimEncoded = sizeHidden\n",
        "        self.conv0 = nn.Conv1d(1, sizeHidden, 10, stride=5, padding=3)\n",
        "        self.batchNorm0 = normLayer(sizeHidden)\n",
        "        self.conv1 = nn.Conv1d(sizeHidden, sizeHidden, 8, stride=4, padding=2)\n",
        "        self.batchNorm1 = normLayer(sizeHidden)\n",
        "        self.conv2 = nn.Conv1d(sizeHidden, sizeHidden, 4,\n",
        "                               stride=2, padding=1)\n",
        "        self.batchNorm2 = normLayer(sizeHidden)\n",
        "        self.conv3 = nn.Conv1d(sizeHidden, sizeHidden, 4, stride=2, padding=1)\n",
        "        self.batchNorm3 = normLayer(sizeHidden)\n",
        "        self.conv4 = nn.Conv1d(sizeHidden, sizeHidden, 4, stride=2, padding=1)\n",
        "        self.batchNorm4 = normLayer(sizeHidden)\n",
        "        self.DOWNSAMPLING = 160\n",
        "\n",
        "    def getDimOutput(self):\n",
        "        return self.conv4.out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.batchNorm0(self.conv0(x)))\n",
        "        x = torch.relu(self.batchNorm1(self.conv1(x)))\n",
        "        x = torch.relu(self.batchNorm2(self.conv2(x)))\n",
        "        x = torch.relu(self.batchNorm3(self.conv3(x)))\n",
        "        x = torch.relu(self.batchNorm4(self.conv4(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class CPCAR(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dimEncoded,\n",
        "                 dimOutput,\n",
        "                 keepHidden,\n",
        "                 nLevelsGRU,\n",
        "                 mode=\"GRU\",\n",
        "                 reverse=False):\n",
        "\n",
        "        super(CPCAR, self).__init__()\n",
        "        self.RESIDUAL_STD = 0.1\n",
        "\n",
        "        if mode == \"LSTM\":\n",
        "            self.baseNet = nn.LSTM(dimEncoded, dimOutput,\n",
        "                                   num_layers=nLevelsGRU, batch_first=True)\n",
        "        elif mode == \"RNN\":\n",
        "            self.baseNet = nn.RNN(dimEncoded, dimOutput,\n",
        "                                  num_layers=nLevelsGRU, batch_first=True)\n",
        "        else:\n",
        "            self.baseNet = nn.GRU(dimEncoded, dimOutput,\n",
        "                                  num_layers=nLevelsGRU, batch_first=True)\n",
        "\n",
        "        self.hidden = None\n",
        "        self.keepHidden = keepHidden\n",
        "        self.reverse = reverse\n",
        "\n",
        "    def getDimOutput(self):\n",
        "        return self.baseNet.hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.reverse:\n",
        "            x = torch.flip(x, [1])\n",
        "        try:\n",
        "            self.baseNet.flatten_parameters()\n",
        "        except RuntimeError:\n",
        "            pass\n",
        "        x, h = self.baseNet(x, self.hidden)\n",
        "        if self.keepHidden:\n",
        "            if isinstance(h, tuple):\n",
        "                self.hidden = tuple(x.detach() for x in h)\n",
        "            else:\n",
        "                self.hidden = h.detach()\n",
        "\n",
        "        # For better modularity, a sequence's order should be preserved\n",
        "        # by each module\n",
        "        if self.reverse:\n",
        "            x = torch.flip(x, [1])\n",
        "        return x\n",
        "\n",
        "\n",
        "class CPCModel(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 AR):\n",
        "        super(CPCModel, self).__init__()\n",
        "        self.gEncoder = encoder\n",
        "        self.gAR = AR\n",
        "\n",
        "    def forward(self, batchData, label):\n",
        "        encodedData = self.gEncoder(batchData).permute(0, 2, 1)\n",
        "        cFeature = self.gAR(encodedData)\n",
        "        return cFeature, encodedData, label\n",
        "\n",
        "\n",
        "class PredictionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nPredicts,\n",
        "                 dimOutputAR,\n",
        "                 dimOutputEncoder,\n",
        "                 dropout=False):\n",
        "\n",
        "        super(PredictionNetwork, self).__init__()\n",
        "        self.predictors = nn.ModuleList()\n",
        "        self.RESIDUAL_STD = 0.01\n",
        "        self.dimOutputAR = dimOutputAR\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5) if dropout else None\n",
        "        for i in range(nPredicts):\n",
        "            self.predictors.append(\n",
        "                nn.Linear(dimOutputAR, dimOutputEncoder, bias=False))\n",
        "            if dimOutputEncoder > dimOutputAR:\n",
        "                residual = dimOutputEncoder - dimOutputAR\n",
        "                self.predictors[-1].weight.data.copy_(torch.cat([torch.randn(\n",
        "                    dimOutputAR, dimOutputAR), self.RESIDUAL_STD * torch.randn(residual, dimOutputAR)], dim=0))\n",
        "\n",
        "    def forward(self, c, candidates):\n",
        "\n",
        "        assert (len(candidates) == len(self.predictors))\n",
        "        out = []\n",
        "\n",
        "        # UGLY\n",
        "        # if isinstance(self.predictors[0], EqualizedConv1d):\n",
        "        # c = c.permute(0, 2, 1)\n",
        "\n",
        "        for k in range(len(self.predictors)):\n",
        "\n",
        "            locC = self.predictors[k](c)\n",
        "            if isinstance(locC, tuple):\n",
        "                locC = locC[0]\n",
        "            # if isinstance(self.predictors[k], EqualizedConv1d):\n",
        "            # locC = locC.permute(0, 2, 1)\n",
        "            if self.dropout is not None:\n",
        "                locC = self.dropout(locC)\n",
        "            locC = locC.view(locC.size(0), 1, locC.size(1), locC.size(2))\n",
        "            outK = (locC * candidates[k]).mean(dim=3)\n",
        "            out.append(outK)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BaseCriterion(nn.Module):\n",
        "    def update(self):\n",
        "        return\n",
        "\n",
        "\n",
        "class CPCUnsupersivedCriterion(BaseCriterion):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nPredicts,  # Number of steps\n",
        "                 dimOutputAR,  # Dimension of G_ar\n",
        "                 dimOutputEncoder,  # Dimension of the convolutional net\n",
        "                 negativeSamplingExt,  # Number of negative samples to draw\n",
        "                 mode=None,\n",
        "                 dropout=False):\n",
        "\n",
        "        super(CPCUnsupersivedCriterion, self).__init__()\n",
        "\n",
        "        self.wPrediction = PredictionNetwork(\n",
        "            nPredicts, dimOutputAR, dimOutputEncoder, dropout=dropout)\n",
        "        self.nPredicts = nPredicts\n",
        "        self.negativeSamplingExt = negativeSamplingExt\n",
        "        self.lossCriterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        if mode not in [None, \"reverse\"]:\n",
        "            raise ValueError(\"Invalid mode\")\n",
        "\n",
        "        self.mode = mode\n",
        "\n",
        "    def sampleClean(self, encodedData, windowSize):\n",
        "\n",
        "        batchSize, nNegativeExt, dimEncoded = encodedData.size()\n",
        "        outputs = []\n",
        "\n",
        "        negExt = encodedData.contiguous().view(-1, dimEncoded)\n",
        "        # Draw nNegativeExt * batchSize negative samples anywhere in the batch\n",
        "        batchIdx = torch.randint(low=0, high=batchSize,\n",
        "                                 size=(self.negativeSamplingExt\n",
        "                                       * windowSize * batchSize,),\n",
        "                                 device=encodedData.device)\n",
        "\n",
        "        seqIdx = torch.randint(low=1, high=nNegativeExt,\n",
        "                               size=(self.negativeSamplingExt\n",
        "                                     * windowSize * batchSize,),\n",
        "                               device=encodedData.device)\n",
        "\n",
        "        baseIdx = torch.arange(0, windowSize, device=encodedData.device)\n",
        "        baseIdx = baseIdx.view(1, 1,\n",
        "                               windowSize).expand(1,\n",
        "                                                  self.negativeSamplingExt,\n",
        "                                                  windowSize).expand(batchSize, self.negativeSamplingExt, windowSize)\n",
        "        seqIdx += baseIdx.contiguous().view(-1)\n",
        "        seqIdx = torch.remainder(seqIdx, nNegativeExt)\n",
        "\n",
        "        extIdx = seqIdx + batchIdx * nNegativeExt\n",
        "        negExt = negExt[extIdx].view(batchSize, self.negativeSamplingExt,\n",
        "                                     windowSize, dimEncoded)\n",
        "\n",
        "        labelLoss = torch.zeros((batchSize * windowSize),\n",
        "                                dtype=torch.long,\n",
        "                                device=encodedData.device)\n",
        "\n",
        "        for k in range(1, self.nPredicts + 1):\n",
        "\n",
        "            # Positive samples\n",
        "            if k < self.nPredicts:\n",
        "                posSeq = encodedData[:, k:-(self.nPredicts - k)]\n",
        "            else:\n",
        "                posSeq = encodedData[:, k:]\n",
        "\n",
        "            posSeq = posSeq.view(batchSize, 1, windowSize, dimEncoded)\n",
        "            fullSeq = torch.cat((posSeq, negExt), dim=1)\n",
        "            outputs.append(fullSeq)\n",
        "\n",
        "        return outputs, labelLoss\n",
        "\n",
        "    def getInnerLoss(self):\n",
        "\n",
        "        return \"orthoLoss\", self.orthoLoss * self.wPrediction.orthoCriterion()\n",
        "\n",
        "    def forward(self, cFeature, encodedData):\n",
        "\n",
        "        if self.mode == \"reverse\":\n",
        "            encodedData = torch.flip(encodedData, [1])\n",
        "            cFeature = torch.flip(cFeature, [1])\n",
        "\n",
        "        batchSize, seqSize, dimAR = cFeature.size()\n",
        "        windowSize = seqSize - self.nPredicts\n",
        "\n",
        "        cFeature = cFeature[:, :windowSize]\n",
        "\n",
        "        sampledData, labelLoss = self.sampleClean(encodedData, windowSize)\n",
        "\n",
        "        predictions = self.wPrediction(cFeature, sampledData)\n",
        "\n",
        "        outLosses = [0 for _ in range(self.nPredicts)]\n",
        "        outAcc = [0 for _ in range(self.nPredicts)]\n",
        "\n",
        "        for k, locPreds in enumerate(predictions[:self.nPredicts]):\n",
        "            locPreds = locPreds.permute(0, 2, 1)  # (batchSize, 1 + negativeSamplingExt, windowSize) to\n",
        "            #                                       (batchSize, windowSize, 1 + negativeSamplingExt)\n",
        "            locPreds = locPreds.contiguous().view(\n",
        "                -1, locPreds.size(2))  # (batchSize, windowSize, 1 + negativeSamplingExt) to\n",
        "            #                            (batchSize * windowSize, 1 + negativeSamplingExt)\n",
        "            lossK = self.lossCriterion(locPreds, labelLoss)\n",
        "            outLosses[k] += lossK.view(1, -1)\n",
        "            _, predsIndex = locPreds.max(1)\n",
        "            outAcc[k] += torch.sum(predsIndex == labelLoss).float().view(1, -1)\n",
        "\n",
        "        return torch.cat(outLosses, dim=1), torch.cat(outAcc, dim=1) / (windowSize * batchSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhJSRs0F43UA"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtqKVS-444yK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from copy import deepcopy\n",
        "# import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "\n",
        "def update_logs(logs, logStep, prevlogs=None):\n",
        "    out = {}\n",
        "    for key in logs:\n",
        "        out[key] = deepcopy(logs[key])\n",
        "\n",
        "        if prevlogs is not None:\n",
        "            out[key] -= prevlogs[key]\n",
        "        out[key] /= logStep\n",
        "    return out\n",
        "\n",
        "\n",
        "def save_logs(data, pathLogs):\n",
        "    with open(pathLogs, 'w') as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "\n",
        "def save_checkpoint(model_state, criterion_state, optimizer_state, best_state,\n",
        "                    path_checkpoint):\n",
        "\n",
        "    state_dict = {\"gEncoder\": model_state,\n",
        "                  \"cpcCriterion\": criterion_state,\n",
        "                  \"optimizer\": optimizer_state,\n",
        "                  \"best\": best_state}\n",
        "\n",
        "    torch.save(state_dict, path_checkpoint)\n",
        "\n",
        "\n",
        "def show_logs(text, logs):\n",
        "    print(\"\")\n",
        "    print('-' * 50)\n",
        "    print(text)\n",
        "\n",
        "    for key in logs:\n",
        "\n",
        "        if key == \"iter\":\n",
        "            continue\n",
        "\n",
        "        nPredicts = logs[key].shape[0]\n",
        "\n",
        "        strSteps = ['Step'] + [str(s) for s in range(1, nPredicts + 1)]\n",
        "        formatCommand = ' '.join(['{:>16}' for _ in range(nPredicts + 1)])\n",
        "        print(formatCommand.format(*strSteps))\n",
        "\n",
        "        strLog = [key] + [\"{:10.6f}\".format(s) for s in logs[key]]\n",
        "        print(formatCommand.format(*strLog))\n",
        "\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "def trainStep(dataLoader,\n",
        "              cpcModel,\n",
        "              cpcCriterion,\n",
        "              optimizer,\n",
        "              loggingStep,\n",
        "              useGPU,\n",
        "              log2Board=0,\n",
        "              totalSteps=0):\n",
        "    cpcModel.train()\n",
        "    cpcCriterion.train()\n",
        "\n",
        "    startTime = time.perf_counter()\n",
        "    n_examples = 0\n",
        "    logs, lastlogs = {}, None\n",
        "    iterCtr = 0\n",
        "\n",
        "    if log2Board > 2:\n",
        "        gradmapGEncoder = {}\n",
        "        gradmapGAR = {}\n",
        "        gradmapWPrediction = {}\n",
        "        if totalSteps == 0:\n",
        "            logWeights(cpcModel.gEncoder, totalSteps)\n",
        "            logWeights(cpcModel.gAR, totalSteps)\n",
        "            logWeights(cpcCriterion.wPrediction, totalSteps)\n",
        "\n",
        "    for step, fulldata in enumerate(dataLoader):\n",
        "        batchData, label = fulldata\n",
        "        n_examples += batchData.size(0)\n",
        "        if useGPU:\n",
        "            batchData = batchData.cuda(non_blocking=True)\n",
        "            label = label.cuda(non_blocking=True)\n",
        "        c_feature, encoded_data, label = cpcModel(batchData, label)\n",
        "        allLosses, allAcc = cpcCriterion(c_feature, encoded_data)\n",
        "        totLoss = allLosses.sum()\n",
        "\n",
        "        totLoss.backward()\n",
        "\n",
        "        if log2Board > 2:\n",
        "            gradmapGEncoder = updateGradientMap(cpcModel.gEncoder, gradmapGEncoder)\n",
        "            gradmapGAR = updateGradientMap(cpcModel.gAR, gradmapGAR)\n",
        "            gradmapWPrediction = updateGradientMap(cpcCriterion.wPrediction, gradmapWPrediction)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if \"locLoss_train\" not in logs:\n",
        "            logs[\"locLoss_train\"] = np.zeros(allLosses.size(1))\n",
        "            logs[\"locAcc_train\"] = np.zeros(allLosses.size(1))\n",
        "\n",
        "        logs[\"locLoss_train\"] += (allLosses.mean(dim=0)).detach().cpu().numpy()\n",
        "        logs[\"locAcc_train\"] += (allAcc.mean(dim=0)).cpu().numpy()\n",
        "        iterCtr += 1\n",
        "\n",
        "        if log2Board > 1:\n",
        "            for t in range(len(logs[\"locLoss_train\"])):\n",
        "                experiment.log_metric(f\"Losses/batch/locLoss_train_{t}\", logs[\"locLoss_train\"][t] / iterCtr, step=totalSteps + iterCtr)\n",
        "                experiment.log_metric(f\"Accuracy/batch/locAcc_train_{t}\", logs[\"locAcc_train\"][t] / iterCtr, step=totalSteps + iterCtr)\n",
        "\n",
        "        if (step + 1) % loggingStep == 0:\n",
        "            new_time = time.perf_counter()\n",
        "            elapsed = new_time - startTime\n",
        "            print(f\"Update {step + 1}\")\n",
        "            print(f\"elapsed: {elapsed:.1f} s\")\n",
        "            print(\n",
        "                f\"{1000.0 * elapsed / loggingStep:.1f} ms per batch, {1000.0 * elapsed / n_examples:.1f} ms / example\")\n",
        "            locLogs = update_logs(logs, loggingStep, lastlogs)\n",
        "            lastlogs = deepcopy(logs)\n",
        "            show_logs(\"Training loss\", locLogs)\n",
        "            startTime, n_examples = new_time, 0\n",
        "            \n",
        "            if log2Board > 2:\n",
        "                # Log gradients\n",
        "                logGradients(gradmapGEncoder, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                logGradients(gradmapGAR, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                logGradients(gradmapWPrediction, totalSteps + iterCtr, scaleBy=1.0 / iterCtr)\n",
        "                # Log weights\n",
        "                logWeights(cpcModel.gEncoder, totalSteps + iterCtr)\n",
        "                logWeights(cpcModel.gAR, totalSteps + iterCtr)\n",
        "                logWeights(cpcCriterion.wPrediction, totalSteps + iterCtr)\n",
        "\n",
        "    logs = update_logs(logs, iterCtr)\n",
        "    logs[\"iter\"] = iterCtr\n",
        "    show_logs(\"Average training loss on epoch\", logs)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def valStep(dataLoader,\n",
        "            cpcModel,\n",
        "            cpcCriterion,\n",
        "            useGPU):\n",
        "    cpcCriterion.eval()\n",
        "    cpcModel.eval()\n",
        "    logs = {}\n",
        "    cpcCriterion.eval()\n",
        "    cpcModel.eval()\n",
        "    iterCtr = 0\n",
        "\n",
        "    for step, fulldata in enumerate(dataLoader):\n",
        "\n",
        "        batchData, label = fulldata\n",
        "\n",
        "        if useGPU:\n",
        "            batchData = batchData.cuda(non_blocking=True)\n",
        "            label = label.cuda(non_blocking=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            c_feature, encoded_data, label = cpcModel(batchData, label)\n",
        "            allLosses, allAcc = cpcCriterion(c_feature, encoded_data)\n",
        "\n",
        "        if \"locLoss_val\" not in logs:\n",
        "            logs[\"locLoss_val\"] = np.zeros(allLosses.size(1))\n",
        "            logs[\"locAcc_val\"] = np.zeros(allLosses.size(1))\n",
        "\n",
        "        iterCtr += 1\n",
        "        logs[\"locLoss_val\"] += allLosses.mean(dim=0).cpu().numpy()\n",
        "        logs[\"locAcc_val\"] += allAcc.mean(dim=0).cpu().numpy()\n",
        "\n",
        "    logs = update_logs(logs, iterCtr)\n",
        "    logs[\"iter\"] = iterCtr\n",
        "    show_logs(\"Validation loss:\", logs)\n",
        "    return logs\n",
        "\n",
        "\n",
        "def updateGradientMap(model, gradMap):\n",
        "    for name, layer in zip(model._modules, model.children()):\n",
        "        if \"activ\" in name:\n",
        "            continue\n",
        "        if not hasattr(layer, \"weight\"):\n",
        "            continue\n",
        "        weightName = \"%s/%s.%s\" % (\"Gradients\", name, \"weight\")\n",
        "        biasName = \"%s/%s.%s\" % (\"Gradients\", name, \"bias\")\n",
        "        gradMap.setdefault(weightName, 0)\n",
        "        gradMap.setdefault(biasName, 0)\n",
        "        gradMap[weightName] += layer.weight.grad\n",
        "        gradMap[biasName] += layer.bias.grad\n",
        "    return gradMap\n",
        "\n",
        "\n",
        "def logGradients(gradMap, step, scaleBy=1.0):\n",
        "    for k, v in gradMap.items():\n",
        "        experiment.log_histogram_3d(v.cpu().detach().numpy() * scaleBy, name=k, step=step)\n",
        "\n",
        "def logWeights(model, step):\n",
        "    for name, layer in zip(model._modules, model.children()):\n",
        "        if \"activ\" in name:\n",
        "            continue\n",
        "        if not hasattr(layer, \"weight\"):\n",
        "            continue\n",
        "        weightName = \"%s/%s.%s\" % (\"Parameters\", name, \"weight\")\n",
        "        biasName = \"%s/%s.%s\" % (\"Parameters\", name, \"bias\")\n",
        "        experiment.log_histogram_3d(layer.weight.cpu().detach().numpy(), name=weightName, step=step)\n",
        "        experiment.log_histogram_3d(layer.bias.cpu().detach().numpy(), name=biasName, step=step)\n",
        "\n",
        "def trainingLoop(trainDataset,\n",
        "                 valDataset,\n",
        "                 batchSize,\n",
        "                 samplingMode,\n",
        "                 cpcModel,\n",
        "                 cpcCriterion,\n",
        "                 nEpoch,\n",
        "                 optimizer,\n",
        "                 pathCheckpoint,\n",
        "                 logs,\n",
        "                 useGPU,\n",
        "                 log2Board=0):\n",
        "    print(f\"Running {nEpoch} epochs\")\n",
        "    startEpoch = len(logs[\"epoch\"])\n",
        "    bestAcc = 0\n",
        "    bestStateDict = None\n",
        "    startTime = time.time()\n",
        "    epoch = 0\n",
        "    totalSteps = 0\n",
        "    try:\n",
        "        for epoch in range(startEpoch, nEpoch):\n",
        "            print(f\"Starting epoch {epoch}\")\n",
        "            trainLoader = trainDataset.getDataLoader(batchSize, samplingMode,\n",
        "                                                    True, numWorkers=0)\n",
        "            valLoader = valDataset.getDataLoader(batchSize, 'sequential', False,\n",
        "                                                numWorkers=0)\n",
        "\n",
        "            print(\"Training dataset %d batches, Validation dataset %d batches, batch size %d\" %\n",
        "                (len(trainLoader), len(valLoader), batchSize))\n",
        "\n",
        "            locLogsTrain = trainStep(trainLoader, cpcModel, cpcCriterion, optimizer, logs[\"logging_step\"], \n",
        "                                        useGPU, log2Board, totalSteps)\n",
        "\n",
        "            totalSteps += locLogsTrain['iter']\n",
        "\n",
        "            locLogsVal = valStep(valLoader, cpcModel, cpcCriterion, useGPU)\n",
        "\n",
        "            print(f'Ran {epoch + 1} epochs '\n",
        "                f'in {time.time() - startTime:.2f} seconds')\n",
        "\n",
        "            if useGPU:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            currentAccuracy = float(locLogsVal[\"locAcc_val\"].mean())\n",
        "            \n",
        "            if log2Board:\n",
        "                for t in range(len(locLogsVal[\"locLoss_val\"])):\n",
        "                    experiment.log_metric(f\"Losses/epoch/locLoss_train_{t}\", locLogsTrain[\"locLoss_train\"][t] / locLogsTrain['iter'], step=epoch)\n",
        "                    experiment.log_metric(f\"Accuracy/epoch/locAcc_train_{t}\", locLogsTrain[\"locAcc_train\"][t] / locLogsTrain['iter'], step=epoch)\n",
        "                    experiment.log_metric(f\"Losses/epoch/locLoss_val_{t}\", locLogsVal[\"locLoss_val\"][t] / locLogsVal['iter'], step=epoch)\n",
        "                    experiment.log_metric(f\"Accuracy/epoch/locAcc_val_{t}\", locLogsVal[\"locAcc_val\"][t] / locLogsVal['iter'], step=epoch)\n",
        "\n",
        "            if currentAccuracy > bestAcc:\n",
        "                bestStateDict = cpcModel.state_dict()\n",
        "\n",
        "            for key, value in dict(locLogsTrain, **locLogsVal).items():\n",
        "                if key not in logs:\n",
        "                    logs[key] = [None for _ in range(epoch)]\n",
        "                if isinstance(value, np.ndarray):\n",
        "                    value = value.tolist()\n",
        "                logs[key].append(value)\n",
        "\n",
        "            logs[\"epoch\"].append(epoch)\n",
        "\n",
        "            if pathCheckpoint is not None and (epoch % logs[\"saveStep\"] == 0 or epoch == nEpoch - 1):\n",
        "                modelStateDict = cpcModel.state_dict()\n",
        "                criterionStateDict = cpcCriterion.state_dict()\n",
        "\n",
        "                save_checkpoint(modelStateDict, criterionStateDict, optimizer.state_dict(), bestStateDict,\n",
        "                                f\"{pathCheckpoint}_{epoch}.pt\")\n",
        "                save_logs(logs, pathCheckpoint + \"_logs.json\")\n",
        "    except KeyboardInterrupt:\n",
        "        if pathCheckpoint is not None:\n",
        "            modelStateDict = cpcModel.state_dict()\n",
        "            criterionStateDict = cpcCriterion.state_dict()\n",
        "\n",
        "            save_checkpoint(modelStateDict, criterionStateDict, optimizer.state_dict(), bestStateDict,\n",
        "                            f\"{pathCheckpoint}_{epoch}_interrupted.pt\")\n",
        "            save_logs(logs, pathCheckpoint + \"_logs.json\")\n",
        "        return\n",
        "\n",
        "def run(trainDataset,\n",
        "        valDataset,\n",
        "        batchSize,\n",
        "        samplingMode,\n",
        "        cpcModel,\n",
        "        cpcCriterion,\n",
        "        nEpoch,\n",
        "        optimizer,\n",
        "        pathCheckpoint,\n",
        "        logs,\n",
        "        useGPU,\n",
        "        log2Board=0):\n",
        "    if log2Board:\n",
        "        with experiment.train():\n",
        "            trainingLoop(trainDataset, valDataset, batchSize, samplingMode, cpcModel, cpcCriterion, nEpoch, optimizer,\n",
        "                         pathCheckpoint, logs, useGPU, log2Board)\n",
        "            experiment.end()\n",
        "    else:\n",
        "        trainingLoop(trainDataset, valDataset, batchSize, samplingMode, cpcModel, cpcCriterion, nEpoch, optimizer, \n",
        "                     pathCheckpoint, logs, useGPU, log2Board)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1undhM04n55"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpthiUBiVZ_W"
      },
      "source": [
        "import torch\n",
        "# from dataloader import AudioBatchData\n",
        "# from model import CPCEncoder, CPCAR, CPCModel, CPCUnsupersivedCriterion\n",
        "# from trainer import run\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1IN1MRVdDy",
        "outputId": "da2276c5-2c52-4621-a2a0-cab65feed347"
      },
      "source": [
        "labelsBy = 'ensemble'\n",
        "print(\"Loading the training dataset\")\n",
        "trainDataset = AudioBatchData(rawAudioPath='data/musicnet_lousy/train_data',\n",
        "                                metadataPath='data/musicnet_lousy/metadata_train.csv',\n",
        "                                sizeWindow=20480,\n",
        "                                labelsBy=labelsBy,\n",
        "                                outputPath='data/musicnet_lousy/train_data/train',\n",
        "                                CHUNK_SIZE=1e9,\n",
        "                                NUM_CHUNKS_INMEM=7)\n",
        "print(\"Training dataset loaded\")\n",
        "print(\"\")\n",
        "\n",
        "print(\"Loading the validation dataset\")\n",
        "valDataset = AudioBatchData(rawAudioPath='data/musicnet_lousy/train_data',\n",
        "                            metadataPath='data/musicnet_lousy/metadata_val.csv',\n",
        "                            sizeWindow=20480,\n",
        "                            labelsBy=labelsBy,\n",
        "                            outputPath='data/musicnet_lousy/train_data/val',\n",
        "                            CHUNK_SIZE=1e9,\n",
        "                            NUM_CHUNKS_INMEM=1)\n",
        "print(\"Validation dataset loaded\")\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the training dataset\n",
            "Chunks already exist at data/musicnet_lousy/train_data/train/ensemble\n",
            "Loading files\n",
            "Loaded 288 sequences, elapsed=161.756 secs\n",
            "Training dataset loaded\n",
            "\n",
            "Loading the validation dataset\n",
            "Chunks already exist at data/musicnet_lousy/train_data/val/ensemble\n",
            "Loading files\n",
            "Loaded 32 sequences, elapsed=30.460 secs\n",
            "Validation dataset loaded\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBri49jRXtf0",
        "outputId": "7dd8a5f5-3797-4395-eef3-ae65164e5e2d"
      },
      "source": [
        "samplingType = 'samesequence'\n",
        "\n",
        "# Encoder network\n",
        "encoderNet = CPCEncoder(512, 'layerNorm')\n",
        "# AR Network\n",
        "arNet = CPCAR(512, 256, samplingType == 'sequential', 1, mode=\"GRU\", reverse=False)\n",
        "\n",
        "cpcModel = CPCModel(encoderNet, arNet)\n",
        "batchSize = 8\n",
        "cpcModel.supervised = False\n",
        "\n",
        "cpcCriterion = CPCUnsupersivedCriterion(nPredicts=12,\n",
        "                                        dimOutputAR=256,\n",
        "                                        dimOutputEncoder=512,\n",
        "                                        negativeSamplingExt=128,\n",
        "                                        mode=None,\n",
        "                                        dropout=False)\n",
        "useGPU = torch.cuda.is_available()\n",
        "\n",
        "if useGPU:\n",
        "    cpcCriterion.cuda()\n",
        "    cpcModel.cuda()\n",
        "\n",
        "gParams = list(cpcCriterion.parameters()) + list(cpcModel.parameters())\n",
        "lr = 2e-4\n",
        "optimizer = torch.optim.Adam(gParams, lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "expDescription = f'{samplingType}_'\n",
        "if samplingType == 'samecategory':\n",
        "    expDescription += f'{labelsBy}_'\n",
        "\n",
        "pathCheckpoint = f'logs/{expDescription}{datetime.now().strftime(\"%d-%m_%H-%M-%S\")}'\n",
        "os.makedirs(pathCheckpoint, exist_ok=True)\n",
        "pathCheckpoint = os.path.join(pathCheckpoint, \"checkpoint\")\n",
        "\n",
        "logs = {\"epoch\": [], \"iter\": [], \"saveStep\": 1, \"logging_step\": 1000}\n",
        "\n",
        "run(trainDataset, valDataset, batchSize, samplingType, cpcModel, cpcCriterion, 30, optimizer, pathCheckpoint, logs, \n",
        "    useGPU, log2Board=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running 30 epochs\n",
            "Starting epoch 0\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 281.3 s\n",
            "281.3 ms per batch, 35.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         4.452355         4.517055         4.563372         4.598594         4.628583         4.652261         4.671071         4.684563         4.698354         4.707054         4.715376         4.720550\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.032782         0.024833         0.021747         0.019591         0.018171         0.017030         0.016126         0.015473         0.014944         0.014547         0.014185         0.016234\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         3.297609         3.538771         3.839180         3.980335         4.100880         4.190617         4.258592         4.312819         4.355414         4.388133         4.415992         4.447540\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.150327         0.092436         0.062300         0.052417         0.046012         0.040897         0.037183         0.034508         0.032367         0.030254         0.028866         0.027268\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 282.0 s\n",
            "282.0 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         2.800761         3.206931         3.674105         3.852995         3.994409         4.099920         4.181202         4.244419         4.291937         4.329880         4.361887         4.396009\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.300470         0.136711         0.073256         0.060889         0.052004         0.046266         0.041737         0.037950         0.034994         0.032897         0.030890         0.029236\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 282.0 s\n",
            "282.0 ms per batch, 35.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         2.221470         2.746527         3.281413         3.517668         3.704200         3.839322         3.949976         4.031446         4.100136         4.153539         4.201104         4.245992\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.500712         0.262349         0.142596         0.116289         0.095297         0.082442         0.071275         0.064429         0.057777         0.053377         0.049227         0.045255\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 282.0 s\n",
            "282.0 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         1.790749         2.403395         3.058969         3.324935         3.535053         3.695769         3.819277         3.916909         3.994566         4.057124         4.111301         4.163559\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.649853         0.354707         0.177707         0.145087         0.118170         0.101017         0.087662         0.077795         0.070015         0.063056         0.057620         0.052926\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 282.1 s\n",
            "282.1 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         1.533853         2.203271         2.940835         3.214537         3.432192         3.598812         3.724734         3.826473         3.908053         3.975398         4.032205         4.087720\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.720926         0.408595         0.193762         0.160827         0.132602         0.113568         0.099190         0.088283         0.079456         0.071509         0.065869         0.060607\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 282.1 s\n",
            "282.1 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         1.286029         2.014767         2.839006         3.124756         3.350324         3.522085         3.654580         3.761777         3.847538         3.920651         3.981709         4.040706\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.776048         0.450501         0.206442         0.170894         0.141706         0.121515         0.105866         0.094922         0.084974         0.077106         0.070569         0.064217\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 282.1 s\n",
            "282.1 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         1.150487         1.888010         2.746255         3.044469         3.278725         3.451426         3.585982         3.696672         3.784605         3.860502         3.923664         3.985356\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.788218         0.475149         0.223348         0.184857         0.152262         0.130980         0.115462         0.101996         0.091893         0.083221         0.075944         0.068977\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 282.3 s\n",
            "282.3 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.993032         1.672101         2.545966         2.866989         3.124948         3.319644         3.470208         3.589945         3.689546         3.771516         3.840701         3.910643\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.831803         0.543066         0.270558         0.221480         0.181317         0.153341         0.132631         0.116588         0.103691         0.093484         0.085284         0.077624\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 282.1 s\n",
            "282.1 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.856623         1.499135         2.413114         2.753965         3.022702         3.229152         3.387974         3.513570         3.616750         3.702367         3.773403         3.846385\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.866675         0.596666         0.292504         0.235640         0.191043         0.159774         0.138128         0.120852         0.107324         0.097459         0.088714         0.080126\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         1.983872         2.519513         3.155372         3.398065         3.591021         3.736658         3.849332         3.938534         4.010780         4.069972         4.119989         4.169681\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.575664         0.346626         0.172091         0.141221         0.116338         0.099476         0.086856         0.077296         0.069474         0.063238         0.058107         0.053464\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.737045         1.277506         2.158419         2.488219         2.747307         2.946773         3.095343         3.219523         3.319905         3.404182         3.476401         3.555842\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.885224         0.650584         0.333521         0.274091         0.227556         0.193853         0.170716         0.151493         0.137037         0.124868         0.116041         0.103608\n",
            "--------------------------------------------------\n",
            "Ran 1 epochs in 3029.80 seconds\n",
            "Starting epoch 1\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 280.5 s\n",
            "280.5 ms per batch, 35.1 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.642586         1.248272         2.248152         2.591236         2.858709         3.068219         3.228399         3.360356         3.468860         3.555992         3.632110         3.705063\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.902730         0.658685         0.312268         0.245987         0.196750         0.160636         0.137124         0.118092         0.102173         0.092343         0.082725         0.074775\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 282.3 s\n",
            "282.3 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.633439         1.188471         2.197959         2.582956         2.874355         3.101939         3.275390         3.414409         3.525817         3.617308         3.696855         3.770940\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.903992         0.685068         0.335815         0.260020         0.205662         0.167322         0.140308         0.120798         0.105764         0.093725         0.083789         0.076013\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.586983         1.116497         2.147865         2.540061         2.836682         3.066647         3.242254         3.383838         3.497977         3.591184         3.671855         3.746432\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.914014         0.708238         0.344575         0.265821         0.209774         0.169744         0.142430         0.122176         0.106328         0.094753         0.084541         0.077109\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 282.3 s\n",
            "282.3 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.551499         1.062085         2.101074         2.496741         2.799932         3.037074         3.219375         3.365498         3.484317         3.581242         3.665757         3.743430\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.917139         0.719972         0.359192         0.282287         0.224752         0.184585         0.155039         0.133547         0.116685         0.104115         0.092170         0.083942\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 282.3 s\n",
            "282.3 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.534743         1.011047         2.014606         2.400492         2.700693         2.939541         3.123119         3.269979         3.393908         3.493940         3.581515         3.664444\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.914620         0.727145         0.380219         0.306464         0.247946         0.204806         0.174039         0.151117         0.132191         0.118015         0.105864         0.095961\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.497149         0.950394         1.935545         2.309508         2.607273         2.847861         3.035090         3.185460         3.314247         3.420175         3.514690         3.601189\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.922384         0.742216         0.397558         0.325654         0.265657         0.220506         0.188053         0.165112         0.143866         0.128393         0.114591         0.103675\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 282.1 s\n",
            "282.1 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.472612         0.917059         1.896971         2.267320         2.561865         2.804602         2.993507         3.144097         3.273754         3.381050         3.475849         3.562441\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.927513         0.750095         0.405889         0.333598         0.273693         0.226483         0.193983         0.170115         0.148973         0.132947         0.118781         0.108058\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.436300         0.856586         1.820811         2.188285         2.484413         2.729668         2.922693         3.077974         3.212809         3.324630         3.422039         3.516116\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.932239         0.764686         0.422296         0.349294         0.288529         0.240825         0.206282         0.181348         0.159464         0.143241         0.128249         0.115880\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.432787         0.842258         1.797564         2.174550         2.474380         2.722026         2.916619         3.070290         3.202527         3.312664         3.408060         3.498340\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.930349         0.767999         0.427635         0.348402         0.285495         0.237265         0.201286         0.176988         0.154878         0.138165         0.124431         0.113050\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.404281         0.796055         1.743182         2.125354         2.430905         2.682680         2.880525         3.037700         3.170695         3.281213         3.377665         3.467786\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.938138         0.783595         0.439556         0.355998         0.290089         0.239531         0.202526         0.177121         0.154641         0.137793         0.124282         0.113048\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.513553         0.989263         1.979098         2.356819         2.652574         2.890302         3.074496         3.222209         3.346105         3.447870         3.536796         3.620004\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.921185         0.733125         0.385009         0.309484         0.250610         0.206644         0.175383         0.152752         0.133503         0.119240         0.106785         0.096936\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.414126         0.761910         1.610073         1.955875         2.235359         2.461796         2.637587         2.781310         2.901790         3.004731         3.092946         3.176786\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.932314         0.781595         0.457247         0.374976         0.311960         0.262913         0.228277         0.202393         0.181530         0.163949         0.149625         0.138005\n",
            "--------------------------------------------------\n",
            "Ran 2 epochs in 6061.89 seconds\n",
            "Starting epoch 2\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 281.0 s\n",
            "281.0 ms per batch, 35.1 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.316382         0.673526         1.655880         2.026059         2.323614         2.568789         2.761256         2.919611         3.056542         3.165714         3.262140         3.355327\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.956523         0.817126         0.447211         0.355614         0.286746         0.233137         0.195370         0.167691         0.144134         0.128058         0.114010         0.101828\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.334659         0.681209         1.669775         2.069908         2.386241         2.643200         2.844307         3.009235         3.144332         3.257272         3.355296         3.447425\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.952206         0.819001         0.451559         0.354355         0.282862         0.228908         0.191284         0.163502         0.141705         0.125307         0.111781         0.100551\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.338708         0.682729         1.663833         2.067456         2.387021         2.643121         2.844530         3.006456         3.141884         3.252656         3.350185         3.440997\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.951040         0.818986         0.453316         0.354509         0.281418         0.226830         0.188374         0.161412         0.138829         0.123374         0.109777         0.099259\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.326043         0.657465         1.629805         2.024361         2.344275         2.603778         2.808768         2.974549         3.113803         3.228976         3.330220         3.424749\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.952934         0.824656         0.464933         0.370575         0.297963         0.242693         0.202782         0.175097         0.151487         0.134731         0.119961         0.107963\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.313886         0.630977         1.596343         1.980346         2.297647         2.557473         2.762258         2.927854         3.069089         3.188160         3.290640         3.387262\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.954380         0.831346         0.474254         0.384455         0.310421         0.254502         0.215024         0.186919         0.161881         0.144048         0.128308         0.116055\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 282.4 s\n",
            "282.4 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.308311         0.610234         1.556953         1.928457         2.240848         2.498727         2.704178         2.871527         3.015003         3.137644         3.242972         3.342242\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.954629         0.836716         0.485224         0.400867         0.328357         0.271413         0.230202         0.201127         0.175575         0.155616         0.139573         0.125263\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.305187         0.600180         1.529104         1.892131         2.199095         2.450883         2.654028         2.820460         2.962814         3.085979         3.192031         3.292204\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.955472         0.839306         0.492940         0.409775         0.337303         0.281116         0.240155         0.210009         0.184145         0.164702         0.147694         0.134196\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 282.3 s\n",
            "282.3 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.293974         0.580245         1.516110         1.885661         2.197529         2.454782         2.661090         2.829625         2.974628         3.098606         3.205071         3.304472\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.956963         0.845520         0.499190         0.413579         0.339492         0.281197         0.239170         0.209014         0.181750         0.161495         0.144569         0.130584\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.286914         0.570856         1.509621         1.876870         2.187806         2.441415         2.647813         2.815122         2.958562         3.080735         3.186321         3.284573\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.957482         0.848477         0.499105         0.411943         0.336531         0.279417         0.237055         0.206753         0.180749         0.161129         0.145240         0.131165\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 282.6 s\n",
            "282.6 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.283761         0.563365         1.500435         1.872763         2.185893         2.438238         2.641202         2.806391         2.947144         3.066457         3.169300         3.265635\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.958928         0.851937         0.501408         0.411111         0.333643         0.276727         0.234745         0.204351         0.178512         0.159518         0.143152         0.130341\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.309252         0.621470         1.578016         1.957737         2.270648         2.525842         2.728917         2.894105         3.034465         3.152372         3.254552         3.350542\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.955312         0.834458         0.478302         0.387784         0.314326         0.258257         0.217960         0.189080         0.164374         0.146204         0.130816         0.118145\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.279021         0.532223         1.403108         1.753329         2.043372         2.274168         2.456771         2.605777         2.731695         2.838809         2.928499         3.016202\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.957216         0.854178         0.518386         0.427896         0.351769         0.292979         0.253805         0.223344         0.198902         0.176855         0.161575         0.148240\n",
            "--------------------------------------------------\n",
            "Ran 3 epochs in 9095.70 seconds\n",
            "Starting epoch 3\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 281.3 s\n",
            "281.3 ms per batch, 35.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.227559         0.473544         1.437863         1.805053         2.107177         2.355417         2.553977         2.716011         2.860039         2.977300         3.078630         3.174657\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.970920         0.877887         0.507108         0.405687         0.327702         0.266737         0.223918         0.192476         0.165005         0.146747         0.130000         0.116008\n",
            "--------------------------------------------------\n",
            "Update 2000\n",
            "elapsed: 282.9 s\n",
            "282.9 ms per batch, 35.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.238492         0.486066         1.448374         1.843489         2.165380         2.428249         2.636470         2.807702         2.954146         3.076175         3.180339         3.276304\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.968463         0.875831         0.510546         0.404113         0.322786         0.259754         0.216770         0.184959         0.158655         0.139448         0.123792         0.111548\n",
            "--------------------------------------------------\n",
            "Update 3000\n",
            "elapsed: 282.9 s\n",
            "282.9 ms per batch, 35.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.241298         0.484546         1.441495         1.841957         2.172211         2.441701         2.650855         2.821116         2.964876         3.084761         3.188074         3.282689\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.968613         0.877962         0.516297         0.406709         0.321497         0.256028         0.213000         0.181671         0.155987         0.137196         0.121751         0.110804\n",
            "--------------------------------------------------\n",
            "Update 4000\n",
            "elapsed: 282.8 s\n",
            "282.8 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.236089         0.473402         1.408611         1.798465         2.131719         2.407794         2.620686         2.792263         2.941173         3.066297         3.172720         3.268527\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.967943         0.877959         0.530094         0.427405         0.342014         0.273985         0.228540         0.197270         0.169434         0.148667         0.131463         0.120696\n",
            "--------------------------------------------------\n",
            "Update 5000\n",
            "elapsed: 282.5 s\n",
            "282.5 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.237008         0.467106         1.366728         1.732028         2.061039         2.347718         2.551537         2.717303         2.870681         3.003170         3.108900         3.206721\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.965614         0.879697         0.551825         0.459615         0.373564         0.296995         0.255027         0.225611         0.193336         0.167431         0.151471         0.140300\n",
            "--------------------------------------------------\n",
            "Update 6000\n",
            "elapsed: 282.8 s\n",
            "282.8 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.226734         0.441790         1.296580         1.627867         1.965924         2.298080         2.498110         2.663490         2.830325         2.978032         3.084665         3.184791\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.963883         0.883779         0.585968         0.509041         0.420255         0.325445         0.285825         0.256508         0.218838         0.185585         0.169000         0.156724\n",
            "--------------------------------------------------\n",
            "Update 7000\n",
            "elapsed: 283.0 s\n",
            "283.0 ms per batch, 35.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.222654         0.423162         1.215106         1.505500         1.834216         2.202191         2.416720         2.584803         2.760329         2.922534         3.039912         3.142935\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.963296         0.888928         0.626325         0.565997         0.483153         0.376294         0.330407         0.298517         0.258498         0.219353         0.197329         0.182267\n",
            "--------------------------------------------------\n",
            "Update 8000\n",
            "elapsed: 282.7 s\n",
            "282.7 ms per batch, 35.3 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.212473         0.389816         1.144609         1.428658         1.748009         2.119250         2.375742         2.544827         2.721344         2.892183         3.021868         3.125180\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.968096         0.903356         0.657513         0.598238         0.517871         0.411314         0.350331         0.318287         0.277511         0.235385         0.208211         0.192352\n",
            "--------------------------------------------------\n",
            "Update 9000\n",
            "elapsed: 282.9 s\n",
            "282.9 ms per batch, 35.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.199001         0.365796         1.130452         1.425943         1.739821         2.087764         2.358277         2.528769         2.694640         2.859834         2.993398         3.095055\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.972159         0.911798         0.658212         0.593310         0.513968         0.416047         0.351111         0.316658         0.279473         0.238761         0.209607         0.193922\n",
            "--------------------------------------------------\n",
            "Update 10000\n",
            "elapsed: 282.9 s\n",
            "282.9 ms per batch, 35.4 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.204036         0.362328         1.132836         1.445256         1.763497         2.106989         2.386836         2.564301         2.730090         2.889161         3.022628         3.123553\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.972518         0.915968         0.659657         0.588310         0.508315         0.411768         0.343360         0.305947         0.269498         0.231820         0.201480         0.186192\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Average training loss on epoch\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.223258         0.433044         1.295021         1.637163         1.960210         2.271509         2.499094         2.668420         2.827241         2.970002         3.084924         3.184161\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.968476         0.890695         0.583731         0.499670         0.417053         0.333013         0.282593         0.250350         0.217087         0.187206         0.166165         0.152629\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "Validation loss:\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "     locLoss_val         0.201456         0.350509         1.053123         1.334720         1.626118         1.926579         2.187827         2.355222         2.507090         2.654272         2.781095         2.875655\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "      locAcc_val         0.970785         0.914799         0.680844         0.615808         0.539403         0.448775         0.374384         0.335679         0.300167         0.256705         0.223739         0.206314\n",
            "--------------------------------------------------\n",
            "Ran 4 epochs in 12133.24 seconds\n",
            "Starting epoch 4\n",
            "Training dataset 10681 batches, Validation dataset 1172 batches, batch size 8\n",
            "Update 1000\n",
            "elapsed: 281.2 s\n",
            "281.2 ms per batch, 35.2 ms / example\n",
            "\n",
            "--------------------------------------------------\n",
            "Training loss\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "   locLoss_train         0.160397         0.298228         1.054292         1.344724         1.648155         1.976789         2.244916         2.434439         2.606877         2.758300         2.894858         2.993198\n",
            "            Step                1                2                3                4                5                6                7                8                9               10               11               12\n",
            "    locAcc_train         0.982168         0.934027         0.679198         0.608185         0.525772         0.428633         0.359629         0.314673         0.272704         0.237439         0.203790         0.189511\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C5V2Ad85OYQ"
      },
      "source": [
        "print(useGPU)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}